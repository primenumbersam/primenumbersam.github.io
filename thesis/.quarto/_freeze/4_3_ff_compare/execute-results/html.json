{
  "hash": "fa52fbc5a6dc94b208504b2e57a13d63",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 03 Benchmarks\nexecute:\n  enabled: true\n---\n\n\n\n\n# Size-Momentum Benchmark\n\n::: {#7bd5cb82 .cell execution_count=1}\n``` {.python .cell-code}\n# Import Libraries\nimport pandas as pd\nimport numpy as np\n\nimport statsmodels.api as sm # QQ plot\nfrom scipy import stats # relative t-test\n\n# graphics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data Frame. Data frequency: Monthly\nstart_date = \"1963-07-01\"\nend_date = \"2023-06-30\"\n\nprint(\"start date:\", start_date)\nprint(\"end date:\", end_date)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstart date: 1963-07-01\nend date: 2023-06-30\n```\n:::\n:::\n\n\n::: {#0406bd43 .cell execution_count=2}\n``` {.python .cell-code}\n#@title Data: Portfolios_Formed_on_ME\n# https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/\n\nimport pandas_datareader as pdr\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning) # FutureWarning 제거\n\n# 'Portfolios_Formed_on_ME', by a Univariate sort on Size (market equity, ME)\n# 3 Potfolios include all NYSE, AMEX, and NASDAQ stocks, but with NYSE breakpoints to divide\n# Size are the bottom 30%, middle 40%, top 30%; quintiles; deciles.\n\npfo_size_raw = pdr.DataReader(\n  name=\"Portfolios_Formed_on_ME\",\n  data_source=\"famafrench\",\n  start=start_date,\n  end=end_date)[0]\n\npfo_size = (pfo_size_raw\n  .reset_index(names=\"date\")\n  .assign(date=lambda x: pd.to_datetime(x[\"date\"].astype(str)))\n  .set_index('date')  # Set the 'date' column as the index\n  .rename(columns=lambda x: x.lower())\n  .rename(columns={'lo 30': 's_30', 'hi 30': 'b_30', 'lo 20': 's_20', 'hi 20': 'b_20', 'lo 10': 's_10', 'hi 10': 'b_10'})\n  .drop(['<= 0'], axis=\"columns\")\n)\n\n# Calculate the average of the small group\n# pfo_size.iloc[:, 8:17].columns.tolist()\npfo_size['s_70'] = pfo_size.iloc[:, 0:2].mean(axis=1)\npfo_size['s_80'] = pfo_size.iloc[:, 3:7].mean(axis=1)\npfo_size['s_90'] = pfo_size.iloc[:, 8:17].mean(axis=1)\n# Drop columns\npfo_size = pfo_size.drop(pfo_size.columns[9:17], axis=1)\npfo_size = pfo_size.drop(pfo_size.columns[4:7], axis=1)\npfo_size = pfo_size.drop(pfo_size.columns[1:2], axis=1)\n\n# Describe\npfo_size.describe().round(2)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>s_30</th>\n      <th>b_30</th>\n      <th>s_20</th>\n      <th>b_20</th>\n      <th>s_10</th>\n      <th>b_10</th>\n      <th>s_70</th>\n      <th>s_80</th>\n      <th>s_90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>720.00</td>\n      <td>720.00</td>\n      <td>720.00</td>\n      <td>720.00</td>\n      <td>720.00</td>\n      <td>720.00</td>\n      <td>720.00</td>\n      <td>720.00</td>\n      <td>720.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.12</td>\n      <td>0.91</td>\n      <td>1.10</td>\n      <td>0.90</td>\n      <td>1.10</td>\n      <td>0.88</td>\n      <td>1.10</td>\n      <td>1.09</td>\n      <td>1.08</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.20</td>\n      <td>4.33</td>\n      <td>6.34</td>\n      <td>4.29</td>\n      <td>6.35</td>\n      <td>4.27</td>\n      <td>5.72</td>\n      <td>5.58</td>\n      <td>5.46</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-29.43</td>\n      <td>-20.80</td>\n      <td>-29.65</td>\n      <td>-20.32</td>\n      <td>-28.87</td>\n      <td>-19.74</td>\n      <td>-28.30</td>\n      <td>-27.82</td>\n      <td>-27.26</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-2.37</td>\n      <td>-1.57</td>\n      <td>-2.41</td>\n      <td>-1.56</td>\n      <td>-2.25</td>\n      <td>-1.53</td>\n      <td>-2.18</td>\n      <td>-1.96</td>\n      <td>-1.92</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.38</td>\n      <td>1.22</td>\n      <td>1.36</td>\n      <td>1.17</td>\n      <td>1.25</td>\n      <td>1.12</td>\n      <td>1.38</td>\n      <td>1.41</td>\n      <td>1.34</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.70</td>\n      <td>3.64</td>\n      <td>4.89</td>\n      <td>3.54</td>\n      <td>4.67</td>\n      <td>3.47</td>\n      <td>4.57</td>\n      <td>4.61</td>\n      <td>4.60</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>26.91</td>\n      <td>17.75</td>\n      <td>27.54</td>\n      <td>18.05</td>\n      <td>29.50</td>\n      <td>18.06</td>\n      <td>24.84</td>\n      <td>23.83</td>\n      <td>23.08</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSummary Statistics for Fama-French Size-Decile Portfolios: Monthly value-weighted excess returns for size-sorted portfolios from July 1963 to June 2023. Excess returns are defined as raw portfolio returns net of the one-month Treasury bill rate.\n\nTo establish a structural benchmark for the TBTF strategy, we begin by examining the historical performance of size-sorted portfolios constructed by Fama and French. In particular, we compare the top and bottom deciles of market capitalization—commonly denoted as `b_10` (large-cap) and `s_10` (small-cap)—using monthly return data spanning from July 1963 to June 2023.\n\nThe data originate from the \"Portfolios Formed on Size (ME)\" dataset provided by the Ken French Data Library. These portfolios, covering NYSE, Nasdaq, and AMEX stocks, are rebalanced annually using NYSE breakpoints and report monthly **value-weighted excess returns**—i.e., returns net of the one-month Treasury bill rate (risk-free return).\n\nFor additional robustness, we construct aggregates (e.g., `s_70`, `s_90`) to represent broader small-cap behavior.\n\n## Motivation\n\nThis section evaluates whether large-cap portfolios exhibit systematically superior **risk-adjusted performance** relative to small-cap portfolios. Such a result would support the hypothesis that TBTF-style strategies derive their advantage not from tactical optimization, but from structural features of the cross-sectional return distribution.\n\n## Methodology\n\nWe compare the `s_10` and `b_10` portfolios in three dimensions:\n\n- **Distributional Shape**: via QQ-plots and skewness asymmetry  \n- **Volatility Profile**: through standard deviation comparisons  \n- **Sharpe Ratio Dynamics**: using time-varying rolling Sharpe ratio curves and volatility–mean coordinate plots\n\nUnlike most academic studies that summarize portfolio performance using static points in mean–volatility space, we propose a dynamic framework in which Sharpe ratios are evaluated as time-series objects. This allows us to capture persistent structural asymmetries.\n\n### Sharpe Ratio Dynamics\n\nWhile static comparisons of mean and volatility offer useful summary insights, they can be misleading in the presence of temporal instability. To capture the **time-varying performance profile** of small- and large-cap portfolios, we construct **rolling Sharpe ratios** using annualized excess returns.\n\nLet $\\mu_t$ and $\\sigma_t$ denote the rolling annualized **excess return mean** and **volatility** of a portfolio over a 36-month window. Then, the rolling Sharpe ratio at time $t$ is computed as:\n\n$$\n\\text{Sharpe}_t = \\frac{\\mu_t}{\\sigma_t}\n$$\n\nWe focus on the bottom and top size deciles: `s_10` (small-cap) and `b_10` (large-cap).\n\n## Key Findings\n\n1. The `b_10` portfolio exhibits consistently lower volatility than `s_10`, across the full 60-year period.\n2. Dynamic Sharpe ratio visualization reveals that the performance advantage of `b_10` is persistent over time, not a byproduct of a particular decade or business cycle.\n3. QQ-plots show that `b_10` excess returns are closer to Gaussian, while `s_10` returns display tail asymmetry—characterized by positive skewness and negative tail risk.\n\nThese results suggest that large-cap portfolios, especially those at the very top of the capitalization spectrum, provide more stable and efficient **excess return profiles**. This supports the structural validity of selecting top-ranked assets by market capitalization in TBTF portfolio construction.\n\n- Over the 60-year period, the **unconditional average annual Sharpe ratio** of `b_10` was **0.99**, compared to **0.74** for `s_10`.\n- The time-series of rolling Sharpe ratios reveals that `b_10` **dominates structurally**, not just in isolated windows.\n- During periods of macroeconomic stress, `s_10` portfolios experience sharper volatility spikes, reducing their Sharpe ratios significantly.\n\n::: {#deff3596 .cell execution_count=3}\n``` {.python .cell-code}\n#@title Time-series of s_10 vs. b_10\n\n# moving average\n# pfo_size_rolling = pfo_size.rolling(window=12).mean()\n\n\n#@title without any overlap between the fiscal years\n# Resample to annual frequency and calculate annual standard deviation\n# groups the monthly data into yearly buckets.\n# annual_std = pfo_size.resample('Y').std() * np.sqrt(12)\n\n# Create a fiscal year column\npfo_size['fiscal_year'] = pfo_size.index.year\npfo_size.loc[pfo_size.index.month >= 7, 'fiscal_year'] = pfo_size.loc[pfo_size.index.month >= 7, 'fiscal_year'] + 1\n\n# Group by fiscal year and calculate annual\nannual_mean = pfo_size.groupby('fiscal_year').mean()*12\nannual_std = pfo_size.groupby('fiscal_year').std() * np.sqrt(12)\n# annual_std.dropna(inplace=True)\n\n#@title Time-series of s_10 vs. b_10\ntemp = annual_mean['s_10'] - annual_mean['b_10']\ntemp.plot()\nplt.axhline(y= temp.mean(), color='r', linestyle='-')\nplt.xlabel('fiscal year')\nplt.ylabel('annual mean difference')\nplt.title('Time-series of s_10 minus b_10 in annual mean')\nplt.show()\nprint('The unconditional mean of the difference is '+str(temp.mean().round(0))+ ' percent, annually')\nprint('\\n')\n\ntemp = annual_std['s_10'] - annual_std['b_10']\ntemp.plot()\nplt.axhline(y= temp.mean(), color='r', linestyle='-')\nplt.xlabel('fiscal year')\nplt.ylabel('annual std difference')\nplt.title('Time-series of s_10 minus b_10 in annual volatility')\nplt.show()\nprint('The unconditional mean of the difference is '+str(temp.mean().round(0))+ ' percent, annually')\nprint('\\n')\n\n# annual_mean and annual_std have the same index\ndf = pd.DataFrame(index=annual_mean.index)\ndf['sr_s_10'] = annual_mean['s_10'] / annual_std['s_10']\ndf['sr_b_10'] = annual_mean['b_10'] / annual_std['b_10']\n\ndf['sr_s_10'].plot()\ndf['sr_b_10'].plot()\nplt.axhline(y= df['sr_s_10'].mean(), color='b', linestyle='dashed')\nplt.axhline(y= df['sr_b_10'].mean(), color='r', linestyle='dashed')\nplt.legend()\nplt.xlabel('fiscal year')\nplt.ylabel('Sharpe Ratio')\nplt.title('Time-series Sharpe Ratios of s_10 and b_10')\nplt.show()\nprint('The unconditional mean Annual Sharpe ratio of s_10 is '+str(df['sr_s_10'].mean().round(2)))\nprint('The unconditional mean Annual Sharpe ratio of b_10 is '+str(df['sr_b_10'].mean().round(2)))\n```\n\n::: {.cell-output .cell-output-display}\n![](4_3_ff_compare_files/figure-html/cell-4-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe unconditional mean of the difference is 3.0 percent, annually\n\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](4_3_ff_compare_files/figure-html/cell-4-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe unconditional mean of the difference is 6.0 percent, annually\n\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](4_3_ff_compare_files/figure-html/cell-4-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe unconditional mean Annual Sharpe ratio of s_10 is 0.74\nThe unconditional mean Annual Sharpe ratio of b_10 is 0.99\n```\n:::\n:::\n\n\n- *Annual excess return difference: `s_10 – b_10`. The red horizontal line marks the long-run average (~3.0% annually).*\n- *Annual volatility difference: `s_10 – b_10`. Large-cap volatility is consistently lower.*\n- *Time-series of 36-month rolling Sharpe ratios for `s_10` and `b_10`. Dashed lines represent the unconditional average for each.*\n\n\nWe also construct a bivariate distribution of annual mean and standard deviation using kernel density estimates:\n\n::: {#e7b3fd3b .cell execution_count=4}\n``` {.python .cell-code}\n#@title s_10 vs. b_10 in the volatility-mean coordinate\n\n# Create a list of category names\ncategories = ['s_10', 'b_10']\n\n# Initialize an empty list to store dataframes\ndfs = []\n\n# Iterate through categories and create melted dataframes\nfor category in categories:\n    # Create a temporary dataframe with selected columns and category label\n    temp_mean = annual_mean[[category]].copy()  # Keep the index\n    temp_mean['category'] = category\n    temp_mean.rename(columns={category: 'annual_mean'}, inplace=True)\n\n    temp_std = annual_std[[category]].copy()  # Keep the index\n    temp_std['category'] = category\n    temp_std.rename(columns={category: 'annual_std'}, inplace=True)\n\n    # Merge the temporary dataframes for mean and std, keeping the index\n    temp_df = pd.merge(temp_mean, temp_std, on=['fiscal_year', 'category'])\n\n    # Append the temporary dataframe to the list\n    dfs.append(temp_df)\n\n# Concatenate all the dataframes in the list into a single dataframe, keeping the index\ndf = pd.concat(dfs, ignore_index=False)\n\n# Now create the displot\nsns.displot(\n    data = df,  # Use the reshaped DataFrame\n    x=\"annual_std\",\n    y=\"annual_mean\",\n    hue=\"category\",  # Use the extracted category for hue\n    kind=\"kde\",\n    rug=True,\n)\nplt.xlabel('annual std')\nplt.ylabel('annual mean')\nplt.title('s_10 vs. b_10 in the volatility-mean coordinate')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](4_3_ff_compare_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\n*Kernel density estimate of annual excess return vs. annual volatility for `s_10` and `b_10`. The separation in volatility–mean space reflects the underlying Sharpe ratio asymmetry.*\n\nThese dynamic plots provide a richer understanding of the **persistent performance asymmetry** between the smallest and largest decile portfolios—supporting the broader structural thesis underlying TBTF.\n\n## Contribution\n\n- Introduces a time-dynamic framework—**Sharpe ratio level curves**—to visualize and quantify structural performance asymmetries between size portfolios.\n- Establishes a long-term empirical benchmark against which TBTF performance can be evaluated.\n- Provides theoretical and empirical justification for focusing on top-market-cap stocks, beyond simple momentum or value signals.\n\n## Appendix {.appendix}\n\n### QQ Plot – `s_10` vs. `b_10`\n\n::: {#2e8970a6 .cell execution_count=5}\n``` {.python .cell-code}\n#@title QQ-plot (정규분포 검사)\n# ![](figs/qqplot_s10_b10.png)\n\nbig = pfo_size['b_10']\nsmall = pfo_size['s_10']\n\nimport statsmodels.api as sm\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n# Calculate the minimum and maximum y-values across both datasets\nmin_y = min(small.min(), big.min())\nmax_y = max(small.max(), big.max())\n\n# QQ plot for 's_low' on the first subplot (ax1)\nsm.qqplot(small, line='s', ax=ax1)\nax1.set_title('Small Portfolio Monthly excess Returns')\nax1.grid(True)\n\n# QQ plot for 'b_low' on the second subplot (ax2)\nsm.qqplot(big, line='s', ax=ax2)\nax2.set_title('Big Portfolio Monthly excess Returns')\nax2.grid(True)\n\n# Set the y-axis limits for both subplots (ax1 and ax2)\nax1.set_ylim([min_y, max_y])\nax2.set_ylim([min_y, max_y])\n# Set x-axis limits of ax2 to be the same as ax1\nxlim = ax1.get_xlim()\nax2.set_xlim(xlim)\n\nplt.tight_layout()  # Adjust spacing between subplots\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](4_3_ff_compare_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\n::: {#eb5ee4f0 .cell execution_count=6}\n``` {.python .cell-code}\n#@title QQ-plot (annualized)\n\nbig = annual_mean['b_10']\nsmall = annual_mean['s_10']\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n# Calculate the minimum and maximum y-values across both datasets\nmin_y = min(small.min(), big.min())\nmax_y = max(small.max(), big.max())\n\n# QQ plot for 's_low' on the first subplot (ax1)\nsm.qqplot(small, line='s', ax=ax1)\nax1.set_title('QQ Plot of small Portfolio Returns')\nax1.grid(True)\n\n# QQ plot for 'b_low' on the second subplot (ax2)\nsm.qqplot(big, line='s', ax=ax2)\nax2.set_title('QQ Plot of big Portfolio Returns')\nax2.grid(True)\n\n# Set the y-axis limits for both subplots (ax1 and ax2)\nax1.set_ylim([min_y, max_y])\nax2.set_ylim([min_y, max_y])\n# Set x-axis limits of ax2 to be the same as ax1\nxlim = ax1.get_xlim()\nax2.set_xlim(xlim)\n\nplt.tight_layout()  # Adjust spacing between subplots\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](4_3_ff_compare_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\n*QQ plots comparing sample quantiles of `s_10` (left) and `b_10` (right) returns to a standard normal distribution. The flatter slope and tighter fit of `b_10` indicate lower volatility and greater normality, while `s_10` exhibits positive skewness and negative tail risk.*\n\n#### QQ Plot Interpretation: Comparing Small vs. Big Size Portfolios\n\nTo evaluate the return distribution characteristics of small-cap and large-cap portfolios, we construct QQ plots of returns for the `s_10` (smallest decile) and `b_10` (largest decile) portfolios. The plots juxtapose sample quantiles against theoretical quantiles from a standard normal distribution. Three notable features emerge:\n\n1. **Slope of the Fitted Line (Volatility Indicator)**  \n   The slope of the QQ line is significantly flatter for the `b_10` portfolio than for the `s_10`.  \n   This reflects **lower empirical standard deviation** for large-cap returns, consistent with their lower volatility and more stable risk profiles. The slope in a QQ plot corresponds to the ratio of sample to theoretical standard deviation, reinforcing the volatility advantage of big stocks.\n\n2. **Line–Scatter Fit (Distributional Regularity)**  \n   The `b_10` plot shows a much tighter fit of the scatter points along the reference line, compared to the `s_10` portfolio.  \n   This implies that large-cap returns conform more closely to the normal distribution. In contrast, the small-cap portfolio exhibits noticeable deviations, suggesting greater skewness, kurtosis, or latent regime switches. The result indicates that large-cap stocks exhibit **greater distributional regularity**, aligning with their more predictable behavior in large institutional portfolios.\n\n3. **Tail Behavior (Asymmetry in Small-Cap Returns)**  \n   For `s_10`, the right tail (positive returns) lies **above** the line, while the left tail (negative returns) lies **below**.  \n   This pattern suggests **positive skewness**—i.e., occasional high positive returns but more frequent or severe downside shocks. Such asymmetry is common in small-cap stocks, which may have explosive upside potential but are also subject to default or delisting risk. The departure from symmetry in `s_10` strengthens the case for mixture modeling and asymmetric tail analysis in the TBTF framework.\n\n\n### Paired T-test (1963–2023)\n\n::: {#7dabc55b .cell execution_count=7}\n``` {.python .cell-code}\n#@title Dependent t-test (annualized mean. Small sample)\n\nsmall = annual_mean['s_10']\nbig = annual_mean['b_10']\n\nt_statistic, p_value = stats.ttest_rel(small, big)\nprint(\"Paired t-test results:\")\nprint(\"t-statistic:\", round(t_statistic,3))\nprint(\"p-value:\", round(p_value,3))\n\n# If the p-value is greater than your significance level (0.05),\n# you would fail to reject the null hypothesis (i.e. not enough evidence to suggest a significant difference)\n\npaired_diff = (small - big)\npaired_diff.hist(bins= len(annual_std) )\nplt.axvline(paired_diff.median(), color='red', linestyle='--')\nplt.title('Paired Mean Difference Histogram')\nplt.xlabel('Annual excess return Difference from small size to big size')\nplt.ylabel('Frequency')\nplt.show()\nprint('The dashed line indicates the median of the difference')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPaired t-test results:\nt-statistic: 0.988\np-value: 0.327\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](4_3_ff_compare_files/figure-html/cell-8-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe dashed line indicates the median of the difference\n```\n:::\n:::\n\n\n::: {#e985b9ac .cell execution_count=8}\n``` {.python .cell-code}\n#@title Dependent t-test (annualized std. Small sample)\n\nsmall = annual_std['s_10']\nbig = annual_std['b_10']\n\nt_statistic, p_value = stats.ttest_rel(small, big)\nprint(\"Paired t-test results:\")\nprint(\"t-statistic:\", round(t_statistic,3))\nprint(\"p-value:\", round(p_value,3))\n\n# If the p-value is greater than your significance level (0.05),\n# you would fail to reject the null hypothesis (i.e. not enough evidence to suggest a significant difference)\n\npaired_diff = (small - big)\npaired_diff.hist(bins= len(annual_std) )\nplt.axvline(paired_diff.median(), color='red', linestyle='--')\nplt.title('Paired Volatility Difference Histogram')\nplt.xlabel('Annual Volatility Difference from small size to big size')\nplt.ylabel('Frequency')\nplt.show()\nprint('The dashed line indicates the median of the difference')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPaired t-test results:\nt-statistic: 7.531\np-value: 0.0\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](4_3_ff_compare_files/figure-html/cell-9-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe dashed line indicates the median of the difference\n```\n:::\n:::\n\n\n",
    "supporting": [
      "4_3_ff_compare_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}