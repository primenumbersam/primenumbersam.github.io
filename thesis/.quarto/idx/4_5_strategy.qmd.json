{"title":"05 Strategy","markdown":{"yaml":{"title":"05 Strategy","format":{"html":{"code-fold":true,"toc":true,"number-sections":true}},"execute":{"enabled":false}},"headingText":"Strategy: Design, Assumptions, and Market Philosophy","containsRefs":false,"markdown":"\n\n\n### Motivation and Theoretical Background\n\nTraditional asset pricing frameworks rest on no-arbitrage principles and risk-return tradeoffs, assuming that all assets exist to offer compensation for exposure to priced risks. Under such models, individual asset returns are interpreted as linear functions of sensitivities to systematic risk factors.\n\nIn contrast, the TBTF (Too Big To Fail) strategy is motivated by a fundamentally different view of financial markets under late-stage capitalism. We argue that the secondary stock market reflects persistent dominance by a small subset of firms whose market power is self-reinforcing. These firms attract new capital not due to risk-efficiency, but due to narrative-driven legitimacy and path-dependent concentration of initial endowment.\n\nThis motivates a strategy grounded not in diversification or risk exposure, but in capital persistence, market lock-in, and capital hierarchy.\n\n\n### Portfolio Selection Rule\n\nThe TBTF strategy is constructed under When-What–How framework:\n\n- **When**: look-back window (in-sample estimation) & look-forward window (rebalancing frequency)\n- **What**: asset universe (e.g. all US-listed stocks) & selection rule (e.g. top-n market cap)\n- **How**: asset weighting scheme (e.g. convex capital concentration fit)\n\n#### Asset Universe\n\nOur strategy operates on the full set of U.S. listed common stocks traded on NYSE, NASDAQ, and AMEX. Stocks with non-positive market capitalization are excluded to avoid bankrupt or illiquid firms.\n\n```{python}\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import skew, kurtosis\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sqlite3\ntbtf = sqlite3.connect(database=\"../../tbtf.sqlite\")\n\ncrsp = pd.read_sql_query(\n  sql=\"SELECT * FROM crsp\",\n  con=tbtf,\n  parse_dates={\"date\"}\n)\n```\n\n#### Ranking and State Formation\n\nEach month, firms are ranked by market capitalization. These rankings define discrete capital states (percentile bins). We focus on the top-decile (state = 10), selecting the top-$n$ firms at time $t$ based on market-cap rank. The baseline is $n=10$, with robustness checks for $n \\in \\{5, 20, 30, 50\\}$.\n\nA Markovian state transition framework is imposed to capture the temporal dynamics of capital flow between ranked states. The top state exhibits persistent and asymmetric capital retention, supporting the capital lock-in hypothesis.\n\n### Asset Weighting Schemes\n\nWe evaluate three portfolio weighting methods:\n\n- **TBTF (Convex Structural Weighting)**:  \n  Capital weights are determined by in-sample estimates of the convex relationship between market-cap rank and capital share. Two specifications are considered:\n\n  - *Quadratic Form*: $w_i \\propto \\alpha + \\beta r_i + \\gamma r_i^2$\n  - *Exponential Form*: $w_i \\propto \\alpha e^{\\beta r_i}$\n  \n  The exponential form better fits observed capital share concentration and ensures structural monotonicity.\n\n- **Value-Weighted (VW)**:  \n  Proportional to each firm’s market capitalization.\n\n- **Equal-Weighted (EQ)**:  \n  Uniform allocation across all selected assets.\n\n```{python}\ndef estimate_exponential_weights(df_in_sample, n=10, state=10):\n    \"\"\"\n    Exponential model 기반으로 특정 state 내 상위 n개 종목의 rank → capshare 관계를 추정.\n    \n    Parameters:\n    - df_in_sample: in-sample CRSP 데이터프레임\n    - n: 각 시점에서 선택할 상위 종목 수\n    - state: 분석 대상 percentile state (e.g., 10 = top 10%)\n\n    Returns:\n    - model_params: {'alpha': α, 'beta': β}\n    - r_squared: 회귀 적합도\n    \"\"\"\n    all_obs = []\n\n    for date, group in df_in_sample[df_in_sample['state'] == state].groupby('date'):\n        group = group.sort_values('mktcap_lag', ascending=False).head(n).copy()\n        if len(group) < n:\n            continue\n\n        group = group.sort_values('mktcap_lag')  # 작은 순으로 정렬\n        group['rank'] = np.arange(1, len(group) + 1)\n        total_cap = group['mktcap_lag'].sum()\n        group['capshare'] = group['mktcap_lag'] / total_cap\n        group['log_capshare'] = np.log(group['capshare'])\n\n        all_obs.append(group[['rank', 'log_capshare']])\n\n    if not all_obs:\n        raise ValueError(\"No valid observations for exponential regression.\")\n\n    df_all = pd.concat(all_obs, ignore_index=True)\n    X = sm.add_constant(df_all['rank'])\n    y = df_all['log_capshare']\n\n    model = sm.OLS(y, X).fit()\n    ln_alpha, beta = model.params\n    alpha = np.exp(ln_alpha)\n\n    return {'alpha': alpha, 'beta': beta}, model.rsquared\n\ndef estimate_quadratic_weights(df_in_sample, n=10, state=10):\n    \"\"\"\n    Rolling in-sample 기간에 대해 top-n 종목에 대한 평균적인 \n    (rank, capshare) 관계를 추정하여 quadratic weight 모델 생성\n    \"\"\"\n    df = df_in_sample[df_in_sample['state'] == state].copy()\n\n    # 각 날짜별로 상위 n개 선택\n    top_n_list = []\n    for date, group in df.groupby('date'):\n        group = group.sort_values('mktcap_lag', ascending=False).head(n)\n        if len(group) < n:\n            continue\n        group = group.sort_values('mktcap_lag')\n        group['rank'] = np.arange(1, len(group) + 1)\n        group['capshare'] = group['mktcap_lag'] / group['mktcap_lag'].sum()\n        top_n_list.append(group[['permno', 'rank', 'capshare']])\n    \n    if not top_n_list:\n        return None, None\n\n    df_all = pd.concat(top_n_list)\n\n    # 회귀 변수 생성\n    df_all['rank_sq'] = df_all['rank'] ** 2\n    X = sm.add_constant(df_all[['rank', 'rank_sq']])\n    y = df_all['capshare']\n\n    # 회귀 수행\n    model = sm.OLS(y, X).fit()\n    \n    return model.params, model.rsquared\n```\n\n```{python}\n\ndef plot_quadratic_fit(df_in_sample, n=10, state=10, ax=None):\n    \"\"\"\n    특정 in-sample에서 주어진 state, top-n 종목에 대한\n    (rank, capshare) 산점도와 quadratic regression fitted line 시각화\n    \"\"\"\n    all_obs = []\n\n    for date, group in df_in_sample[df_in_sample['state'] == state].groupby('date'):\n        group = group.sort_values('mktcap_lag', ascending=False).head(n).copy()\n        if len(group) < n:\n            continue\n\n        group = group.sort_values('mktcap_lag')  # rank: 1 = smallest\n        group['rank'] = np.arange(1, len(group) + 1)\n        total_cap = group['mktcap_lag'].sum()\n        group['capshare'] = group['mktcap_lag'] / total_cap\n\n        all_obs.append(group[['rank', 'capshare']])\n\n    if not all_obs:\n        raise ValueError(\"No valid observations for fitting.\")\n\n    df_all = pd.concat(all_obs, ignore_index=True)\n    df_all['rank_sq'] = df_all['rank'] ** 2\n\n    # 회귀\n    X = sm.add_constant(df_all[['rank', 'rank_sq']])\n    y = df_all['capshare']\n    model = sm.OLS(y, X).fit()\n\n    # 추정 계수\n    alpha, beta, gamma = model.params\n\n    # Fitted curve\n    rank_grid = np.linspace(df_all['rank'].min(), df_all['rank'].max(), 100)\n    fitted_curve = alpha + beta * rank_grid + gamma * rank_grid**2\n\n    # 시각화\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(8, 5))\n    ax.scatter(df_all['rank'], df_all['capshare'], alpha=0.4, label='Observed', color='steelblue')\n    ax.plot(rank_grid, fitted_curve, color='darkgreen', linewidth=2.5, label='Quadratic Fit')\n    ax.set_title(f\"Quadratic Fit (state={state}, n={n})\")\n    ax.set_xlabel(\"Rank\")\n    ax.set_ylabel(\"Capital Share\")\n    ax.legend()\n    ax.grid(True)\n\n    return \n\ndef plot_exponential_fit(df_in_sample, n=10, state=10, ax=None):\n    \"\"\"\n    특정 in-sample에서 주어진 state, top-n 종목에 대한\n    (rank, capshare) 산점도와 exponential regression fitted line 시각화\n    \"\"\"\n\n    all_obs = []\n\n    for date, group in df_in_sample[df_in_sample['state'] == state].groupby('date'):\n        group = group.sort_values('mktcap_lag', ascending=False).head(n).copy()\n        if len(group) < n:\n            continue\n\n        group = group.sort_values('mktcap_lag')  # 작은 순서대로 재정렬\n        group['rank'] = np.arange(1, len(group) + 1)\n        total_cap = group['mktcap_lag'].sum()\n        group['capshare'] = group['mktcap_lag'] / total_cap\n\n        all_obs.append(group[['rank', 'capshare']])\n\n    if not all_obs:\n        raise ValueError(\"No valid observations for fitting.\")\n\n    df_all = pd.concat(all_obs, ignore_index=True)\n    df_all['log_capshare'] = np.log(df_all['capshare'])\n\n    # 회귀\n    X = sm.add_constant(df_all['rank'])\n    y = df_all['log_capshare']\n    model = sm.OLS(y, X).fit()\n\n    # 추정 계수\n    ln_alpha, beta = model.params\n    alpha = np.exp(ln_alpha)\n\n    # Fitted curve\n    rank_grid = np.linspace(df_all['rank'].min(), df_all['rank'].max(), 100)\n    fitted_curve = alpha * np.exp(beta * rank_grid)\n\n    # 시각화\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(8, 5))\n    ax.scatter(df_all['rank'], df_all['capshare'], alpha=0.4, label='Observed', color='steelblue')\n    ax.plot(rank_grid, fitted_curve, color='darkred', linewidth=2.5, label='Exponential Fit')\n    ax.set_title(f\"Exponential Fit (state={state}, n={n})\")\n    ax.set_xlabel(\"Rank\")\n    ax.set_ylabel(\"Capital Share\")\n    ax.legend()\n    ax.grid(True)\n\n    return \n```\n\n#### Empirical Fit of Capital Share Functions\n\nTo empirically validate the structural weighting functions, we fit both quadratic and exponential models to the in-sample relationship between rank and capital share. The following plots show the cross-sectional fitting results based on a representative rebalance date.\n\n\n```{python}\ndef split_in_out_sample(df, in_end, in_sample_months=36, out_end=None):\n    \"\"\"\n    주어진 in_end와 in_sample_months, 그리고 선택적으로 out_end를 이용해 \n    in-sample과 out-of-sample 데이터를 분할합니다.\n    \n    Parameters:\n      - df: 전체 데이터프레임 (반드시 'date' 컬럼이 있어야 함)\n      - in_end: in-sample 종료일 (string 또는 datetime)\n      - in_sample_months: in-sample 기간 (월 단위, default 36)\n      - out_end: out-of-sample 종료일 (string 또는 datetime). None인 경우 in_end 이후 전체가 out-of-sample.\n    \n    Returns:\n      - in_sample: [in_end - in_sample_months, in_end] 기간의 데이터프레임\n      - out_sample: (in_end, out_end] 또는 in_end 이후 전체 데이터프레임\n    \"\"\"\n    df = df.copy()\n    df['date'] = pd.to_datetime(df['date'])\n    in_end = pd.to_datetime(in_end)\n    \n    # in-sample 기간 계산\n    in_start = in_end - pd.DateOffset(months=in_sample_months)\n    in_sample = df[(df['date'] >= in_start) & (df['date'] <= in_end)].copy()\n    \n    # out-of-sample 기간 계산\n    if out_end is not None:\n        out_end = pd.to_datetime(out_end)\n        out_sample = df[(df['date'] > in_end) & (df['date'] <= out_end)].copy()\n    else:\n        out_sample = df[df['date'] > in_end].copy()\n    \n    return in_sample, out_sample\n```\n\n```{python}\nin_end = '2009-12-31'\nin_sample_months = 48\n\nprint('Snapshot at:', in_end)\nprint('Look-back period:', in_sample_months, 'months')\n\ndf_in_sample, _ = split_in_out_sample(crsp, in_end, in_sample_months)\n```\n\n```{python}\n#| fig-cap: \"Quadratic vs. Exponential Fit at 2009-12-31\"\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nplot_quadratic_fit(df_in_sample, n=10, state=10, ax=axes[0])\nplot_exponential_fit(df_in_sample, n=10, state=10, ax=axes[1])\n\nfig.suptitle(f\"Fitted Capital Share Functions at {in_end}\")\nplt.tight_layout()\n```\n\n```{python}\nin_end = '2023-12-31'\nin_sample_months = 48\n\nprint('Snapshot at:', in_end)\nprint('Look-back period:', in_sample_months, 'months')\n\ndf_in_sample, _ = split_in_out_sample(crsp, in_end, in_sample_months)\n```\n\n```{python}\n#| fig-cap: \"Quadratic vs. Exponential Fit at 2023-12-31\"\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nplot_quadratic_fit(df_in_sample, n=10, state=10, ax=axes[0])\nplot_exponential_fit(df_in_sample, n=10, state=10, ax=axes[1])\n\nfig.suptitle(f\"Fitted Capital Share Functions at {in_end}\")\nplt.tight_layout()\n```\n\nThese cross-sectional plots confirm the superiority of the exponential fit in capturing the accelerating concentration of capital among top-ranked firms. The difference is especially pronounced in the post-2010 sample, reflecting a structural shift in capital dynamics during the QE era.\n\nThe exponential fit exhibits stronger monotonicity and structural convexity, particularly in the top-ranked firms, supporting its use in the TBTF weighting scheme.\n\n\n### Rebalancing Frequency\n\nWe test fixed-interval rebalancing schemes:\n\n- Monthly (default)\n- Quarterly\n- Semiannual\n- Annual\n\nRebalancing frequency directly affects turnover and transaction cost implications. Monthly rebalancing is selected as the baseline to balance responsiveness with frictions.\n\n\n### Benchmark Portfolios\n\nFor external comparison, we use:\n\n- **Pre-2010 Index Benchmarks**: Dow Jones Industrial Average (^DJI), Nasdaq-100 (^NDX)\n- **Post-2010 Index ETFs**: \n  - DIA (ETF version of DJIA, State Street Corporation ETF. Fund inception: 1998/01/14), \n  - QQQ (ETF version of NDX. Nasdaq-100 ticker. the Invesco QQQ Trust. Fund inception: 1999/03/10), \n  - SPY (The SPDR S&P 500 ETF, Fund inception: 1993/01/22), \n  - VTI (Vanguard Total Stock Market ETF, Fund inception: 2001년 5월 24일), \n- **Post-2010 Style Portfolios**: Fama-French ME5 × PRIOR1/3/5, constructed with rolling monthly value- or equal-weighting\n\n\n### Strategic Rationale\n\nThe TBTF strategy is not merely a rule-based selection method. It reflects a structural argument that allocative efficiency in modern markets is compromised by persistent capital concentration. Instead of diversifying away idiosyncratic risk, markets are increasingly dominated by capital lock-in, hierarchy reinforcement, and narrative legitimacy.\n\nThis framework reconceptualizes the role of financial assets from carriers of risk to vehicles of structural dominance, and evaluates portfolio construction in light of this altered paradigm.\n\n\n## Appendix: TBTF Strategy Pipeline {.appendix}\n\nThis section outlines the modular structure of the TBTF portfolio strategy, from input specification to out-of-sample return generation and performance evaluation. The pipeline is designed to be flexible across different weighting schemes, rebalance frequencies, and strategy parameters.\n\n### Inputs (Arguments)\n\n| Argument | Description |\n|----------|-------------|\n| `df` | Main input DataFrame (`crsp`) including fields such as `date`, `permno`, `mktcap`, `ret`, `state`, `mktcap_lag`, etc. |\n| `state_level` | Target capital state to define the asset universe, typically the top decile (e.g., `10`). |\n| `top_n` | Number of assets to be selected at each rebalance point (e.g., `n ∈ {5, 10, 20, 30, 50}`). |\n| `rebalance_freq` | Rebalancing interval (e.g., `'1M'`, `'3M'`, `'6M'`, `'12M'`). |\n| `weighting_method` | One of `'equal'`, `'value'`, `'quadratic'`, or `'exponential'`. |\n| `in_sample_period` | Estimation window for in-sample weight calibration (e.g., `'2010-01-01'` to `'2013-12-31'`). |\n| `out_sample_period` | Evaluation window for out-of-sample backtesting (e.g., `'2014-01-01'` to `'2023-12-31'`). |\n| `eta`, `p` | Parameters for CRRA utility (`eta`) and Omega ratio threshold (`p`). |\n\n\n### Strategy Pipeline (Pseudo-code Logic)\n\n#### Step 1: Data Partitioning & Filtering\n\n```python\nin_sample = df[(df['date'] >= in_sample_start) & (df['date'] <= in_sample_end)]\nout_sample = df[(df['date'] > in_sample_end) & (df['date'] <= out_sample_end)]\nuniverse = df[df['state'] == state_level]\n```\n\n- Restrict selection universe to target capital state (e.g., top decile).\n\n\n#### Step 2: In-sample Weight Estimation\n\nIf `weighting_method` is `'quadratic'` or `'exponential'`:\n\n- Estimate the relationship between within-state rank and capital share using in-sample data:\n  - Quadratic:  \n    $$\\text{CapShare}_i = \\alpha + \\beta \\cdot \\text{Rank}_i + \\gamma \\cdot \\text{Rank}_i^2$$\n  - Exponential:  \n    $$\\text{CapShare}_i = \\alpha \\cdot e^{\\beta \\cdot \\text{Rank}_i}$$\n- Save estimated coefficients:\n  ```python\n  coefficients = {'alpha': ..., 'beta': ..., 'gamma': ...}\n  ```\n\n#### Step 3: Out-of-sample Portfolio Construction\n\nFor each rebalance date in the out-sample period:\n\n1. Filter to target state (`state == state_level`)\n2. Rank by market cap, select top `n`\n3. Assign weights:\n   - Equal: $w_i = 1/n$\n   - Value: $w_i = \\text{mktcap}_i / \\sum \\text{mktcap}$\n   - Quadratic: apply $\\hat{\\alpha}, \\hat{\\beta}, \\hat{\\gamma}$ to rank\n   - Exponential: apply $\\hat{\\alpha}, \\hat{\\beta}$ to rank\n4. Store `[date, permno, weight]` for forward return application\n\n\n#### Step 4: Portfolio Return Computation\n\nAt each evaluation date after rebalance:\n\n- Merge forward returns of selected assets\n- Compute portfolio return:\n  $$R_t^{\\text{portfolio}} = \\sum_i w_{i,t} \\cdot r_{i,t}$$\n- Construct time series of out-of-sample portfolio returns\n\n\n#### Step 5: Turnover Calculation\n\nFor each rebalance window:\n\n- Calculate:\n  $$\\text{Turnover}_t = \\sum_i |w_{i,t} - w_{i,t-1}|$$\n- Useful for assessing transaction costs and liquidity requirements\n\n\n#### Step 6: Performance Evaluation\n\nUsing out-of-sample return series, compute:\n\n- **Risk-Adjusted Metrics**:\n  - Sharpe ratio, Sortino ratio\n  - Omega ratio (threshold = `p`)\n  - Calmar ratio, maximum drawdown (MDD)\n  - CRRA utility with risk aversion parameter `eta`\n\n- Return summary as dictionary:\n  ```python\n  metrics_dict = {\n      'Sharpe': ...,\n      'Sortino': ...,\n      'Omega': ...,\n      'CRRA': ...,\n      'CAGR': ...,\n      'MDD': ...\n  }\n  ```\n\n\n### Outputs\n\n| Output | Description |\n|--------|-------------|\n| `returns_df` | Time series of out-of-sample portfolio returns |\n| `weights_df` | Portfolio composition (weights per date and permno) |\n| `turnover_df` | Time series of turnover at each rebalance point |\n| `metrics_dict` | Dictionary of strategy performance metrics |\n\n### Module Lits\n\n```python\n#| label: TBTF Strategy Full Module\n#| warning: false\n#| message: false\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import skew, kurtosis\n\n# ----------------------------\n# 1. Data Partitioning\n# ----------------------------\ndef split_in_out_sample(df, in_end, in_sample_months=36, out_end=None):\n    in_sample = df[(df['date'] <= in_end)].copy()\n    if out_end:\n        out_sample = df[(df['date'] > in_end) & (df['date'] <= out_end)].copy()\n    else:\n        out_sample = df[(df['date'] > in_end)].copy()\n    return in_sample, out_sample\n\n# ----------------------------\n# 2. Weight Estimation\n# ----------------------------\ndef estimate_exponential_weights(df_in_sample, n=10, state=10):\n    df = df_in_sample[df_in_sample['state'] == state].copy()\n    df['rank'] = df.groupby('date')['mktcap'].rank(ascending=True, method='first')\n    df = df[df['rank'] <= n]\n    df['log_capshare'] = np.log(df['mktcap'] / df.groupby('date')['mktcap'].transform('sum'))\n    X = df[['rank']]\n    X = sm.add_constant(X)\n    y = df['log_capshare']\n    model = sm.OLS(y, X).fit()\n    return {'alpha': np.exp(model.params['const']), 'beta': model.params['rank']}\n\ndef estimate_quadratic_weights(df_in_sample, n=10, state=10):\n    df = df_in_sample[df_in_sample['state'] == state].copy()\n    df['rank'] = df.groupby('date')['mktcap'].rank(ascending=True, method='first')\n    df = df[df['rank'] <= n]\n    df['capshare'] = df['mktcap'] / df.groupby('date')['mktcap'].transform('sum')\n    df['rank_sq'] = df['rank'] ** 2\n    X = df[['rank', 'rank_sq']]\n    X = sm.add_constant(X)\n    y = df['capshare']\n    model = sm.OLS(y, X).fit()\n    return {'alpha': model.params['const'], 'beta': model.params['rank'], 'gamma': model.params['rank_sq']}\n\n# ----------------------------\n# 3. Portfolio Construction\n# ----------------------------\ndef construct_tbtf_exponential(crsp_df, target_state, top_n, params):\n    df = crsp_df[crsp_df['state'] == target_state].copy()\n    df['rank'] = df.groupby('date')['mktcap'].rank(ascending=True, method='first')\n    df = df[df['rank'] <= top_n]\n    df['weight'] = params['alpha'] * np.exp(params['beta'] * df['rank'])\n    df['weight'] = df['weight'] / df.groupby('date')['weight'].transform('sum')\n    return df[['date', 'permno', 'weight']]\n\ndef construct_tbtf_quadratic(crsp_df, target_state, top_n, params):\n    df = crsp_df[crsp_df['state'] == target_state].copy()\n    df['rank'] = df.groupby('date')['mktcap'].rank(ascending=True, method='first')\n    df = df[df['rank'] <= top_n]\n    df['rank_sq'] = df['rank'] ** 2\n    df['weight'] = params['alpha'] + params['beta'] * df['rank'] + params['gamma'] * df['rank_sq']\n    df['weight'] = df['weight'] / df.groupby('date')['weight'].transform('sum')\n    return df[['date', 'permno', 'weight']]\n\n# ----------------------------\n# 4. Return and Turnover Calculation\n# ----------------------------\ndef compute_return_tbtf(crsp, rebalance_dates, weighting_method='exponential', top_n=10, state=10, in_sample_months=36):\n    # Placeholder for full implementation\n    pass\n\ndef compute_return_pfo(crsp, rebalance_dates, weighting_method='vw', top_n=10):\n    # Placeholder for traditional VW or EW method\n    pass\n\ndef compute_turnover(weights_df, rebalance_dates):\n    turnover_list = []\n    prev_weights = None\n    for date in rebalance_dates:\n        w = weights_df[weights_df['date'] == date].set_index('permno')['weight']\n        if prev_weights is not None:\n            turnover = (w - prev_weights).abs().sum()\n            turnover_list.append({'date': date, 'turnover': turnover})\n        prev_weights = w\n    return pd.DataFrame(turnover_list)\n\n# ----------------------------\n# 5. Performance Evaluation\n# ----------------------------\ndef evaluate_performance(returns, eta=3, p=0.01, periods_per_year=12):\n    mu = returns.mean() * periods_per_year\n    sigma = returns.std() * np.sqrt(periods_per_year)\n    sharpe = mu / sigma if sigma != 0 else np.nan\n    sortino = mu / returns[returns < 0].std() if returns[returns < 0].std() != 0 else np.nan\n    omega = (returns[returns > p] - p).sum() / abs((returns[returns <= p] - p).sum())\n    crra_utility = (1 / (1 - eta)) * (1 + returns).apply(lambda x: x**(1 - eta) - 1).mean() if eta != 1 else np.log(1 + returns).mean()\n    return {\n        'Sharpe': sharpe,\n        'Sortino': sortino,\n        'Omega': omega,\n        'CRRA': crra_utility,\n        'Mean': mu,\n        'Volatility': sigma\n    }\n\n# ----------------------------\n# 6. Rebalance Date Utility\n# ----------------------------\ndef get_rebalance_offset(rebalance_freq):\n    offset_map = {'1M': 1, '3M': 3, '6M': 6, '12M': 12}\n    return offset_map.get(rebalance_freq, 1)\n\n# ----------------------------\n# 7. Backtest Pipeline\n# ----------------------------\ndef backtest_pipeline(crsp, in_end, out_end, in_sample_months, rebalance_freq, weighting_method, top_n, state, eta, p):\n    # Placeholder for full backtest execution logic\n    pass\n\n# ----------------------------\n# 8. Visualization (optional)\n# ----------------------------\ndef plot_quadratic_fit(df_in_sample, n=10, state=10):\n    # Placeholder for plot generation\n    pass\n\ndef plot_exponential_fit(df_in_sample, n=10, state=10):\n    # Placeholder for plot generation\n    pass\n\n```\n\n","srcMarkdownNoYaml":"\n\n## Strategy: Design, Assumptions, and Market Philosophy\n\n### Motivation and Theoretical Background\n\nTraditional asset pricing frameworks rest on no-arbitrage principles and risk-return tradeoffs, assuming that all assets exist to offer compensation for exposure to priced risks. Under such models, individual asset returns are interpreted as linear functions of sensitivities to systematic risk factors.\n\nIn contrast, the TBTF (Too Big To Fail) strategy is motivated by a fundamentally different view of financial markets under late-stage capitalism. We argue that the secondary stock market reflects persistent dominance by a small subset of firms whose market power is self-reinforcing. These firms attract new capital not due to risk-efficiency, but due to narrative-driven legitimacy and path-dependent concentration of initial endowment.\n\nThis motivates a strategy grounded not in diversification or risk exposure, but in capital persistence, market lock-in, and capital hierarchy.\n\n\n### Portfolio Selection Rule\n\nThe TBTF strategy is constructed under When-What–How framework:\n\n- **When**: look-back window (in-sample estimation) & look-forward window (rebalancing frequency)\n- **What**: asset universe (e.g. all US-listed stocks) & selection rule (e.g. top-n market cap)\n- **How**: asset weighting scheme (e.g. convex capital concentration fit)\n\n#### Asset Universe\n\nOur strategy operates on the full set of U.S. listed common stocks traded on NYSE, NASDAQ, and AMEX. Stocks with non-positive market capitalization are excluded to avoid bankrupt or illiquid firms.\n\n```{python}\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import skew, kurtosis\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sqlite3\ntbtf = sqlite3.connect(database=\"../../tbtf.sqlite\")\n\ncrsp = pd.read_sql_query(\n  sql=\"SELECT * FROM crsp\",\n  con=tbtf,\n  parse_dates={\"date\"}\n)\n```\n\n#### Ranking and State Formation\n\nEach month, firms are ranked by market capitalization. These rankings define discrete capital states (percentile bins). We focus on the top-decile (state = 10), selecting the top-$n$ firms at time $t$ based on market-cap rank. The baseline is $n=10$, with robustness checks for $n \\in \\{5, 20, 30, 50\\}$.\n\nA Markovian state transition framework is imposed to capture the temporal dynamics of capital flow between ranked states. The top state exhibits persistent and asymmetric capital retention, supporting the capital lock-in hypothesis.\n\n### Asset Weighting Schemes\n\nWe evaluate three portfolio weighting methods:\n\n- **TBTF (Convex Structural Weighting)**:  \n  Capital weights are determined by in-sample estimates of the convex relationship between market-cap rank and capital share. Two specifications are considered:\n\n  - *Quadratic Form*: $w_i \\propto \\alpha + \\beta r_i + \\gamma r_i^2$\n  - *Exponential Form*: $w_i \\propto \\alpha e^{\\beta r_i}$\n  \n  The exponential form better fits observed capital share concentration and ensures structural monotonicity.\n\n- **Value-Weighted (VW)**:  \n  Proportional to each firm’s market capitalization.\n\n- **Equal-Weighted (EQ)**:  \n  Uniform allocation across all selected assets.\n\n```{python}\ndef estimate_exponential_weights(df_in_sample, n=10, state=10):\n    \"\"\"\n    Exponential model 기반으로 특정 state 내 상위 n개 종목의 rank → capshare 관계를 추정.\n    \n    Parameters:\n    - df_in_sample: in-sample CRSP 데이터프레임\n    - n: 각 시점에서 선택할 상위 종목 수\n    - state: 분석 대상 percentile state (e.g., 10 = top 10%)\n\n    Returns:\n    - model_params: {'alpha': α, 'beta': β}\n    - r_squared: 회귀 적합도\n    \"\"\"\n    all_obs = []\n\n    for date, group in df_in_sample[df_in_sample['state'] == state].groupby('date'):\n        group = group.sort_values('mktcap_lag', ascending=False).head(n).copy()\n        if len(group) < n:\n            continue\n\n        group = group.sort_values('mktcap_lag')  # 작은 순으로 정렬\n        group['rank'] = np.arange(1, len(group) + 1)\n        total_cap = group['mktcap_lag'].sum()\n        group['capshare'] = group['mktcap_lag'] / total_cap\n        group['log_capshare'] = np.log(group['capshare'])\n\n        all_obs.append(group[['rank', 'log_capshare']])\n\n    if not all_obs:\n        raise ValueError(\"No valid observations for exponential regression.\")\n\n    df_all = pd.concat(all_obs, ignore_index=True)\n    X = sm.add_constant(df_all['rank'])\n    y = df_all['log_capshare']\n\n    model = sm.OLS(y, X).fit()\n    ln_alpha, beta = model.params\n    alpha = np.exp(ln_alpha)\n\n    return {'alpha': alpha, 'beta': beta}, model.rsquared\n\ndef estimate_quadratic_weights(df_in_sample, n=10, state=10):\n    \"\"\"\n    Rolling in-sample 기간에 대해 top-n 종목에 대한 평균적인 \n    (rank, capshare) 관계를 추정하여 quadratic weight 모델 생성\n    \"\"\"\n    df = df_in_sample[df_in_sample['state'] == state].copy()\n\n    # 각 날짜별로 상위 n개 선택\n    top_n_list = []\n    for date, group in df.groupby('date'):\n        group = group.sort_values('mktcap_lag', ascending=False).head(n)\n        if len(group) < n:\n            continue\n        group = group.sort_values('mktcap_lag')\n        group['rank'] = np.arange(1, len(group) + 1)\n        group['capshare'] = group['mktcap_lag'] / group['mktcap_lag'].sum()\n        top_n_list.append(group[['permno', 'rank', 'capshare']])\n    \n    if not top_n_list:\n        return None, None\n\n    df_all = pd.concat(top_n_list)\n\n    # 회귀 변수 생성\n    df_all['rank_sq'] = df_all['rank'] ** 2\n    X = sm.add_constant(df_all[['rank', 'rank_sq']])\n    y = df_all['capshare']\n\n    # 회귀 수행\n    model = sm.OLS(y, X).fit()\n    \n    return model.params, model.rsquared\n```\n\n```{python}\n\ndef plot_quadratic_fit(df_in_sample, n=10, state=10, ax=None):\n    \"\"\"\n    특정 in-sample에서 주어진 state, top-n 종목에 대한\n    (rank, capshare) 산점도와 quadratic regression fitted line 시각화\n    \"\"\"\n    all_obs = []\n\n    for date, group in df_in_sample[df_in_sample['state'] == state].groupby('date'):\n        group = group.sort_values('mktcap_lag', ascending=False).head(n).copy()\n        if len(group) < n:\n            continue\n\n        group = group.sort_values('mktcap_lag')  # rank: 1 = smallest\n        group['rank'] = np.arange(1, len(group) + 1)\n        total_cap = group['mktcap_lag'].sum()\n        group['capshare'] = group['mktcap_lag'] / total_cap\n\n        all_obs.append(group[['rank', 'capshare']])\n\n    if not all_obs:\n        raise ValueError(\"No valid observations for fitting.\")\n\n    df_all = pd.concat(all_obs, ignore_index=True)\n    df_all['rank_sq'] = df_all['rank'] ** 2\n\n    # 회귀\n    X = sm.add_constant(df_all[['rank', 'rank_sq']])\n    y = df_all['capshare']\n    model = sm.OLS(y, X).fit()\n\n    # 추정 계수\n    alpha, beta, gamma = model.params\n\n    # Fitted curve\n    rank_grid = np.linspace(df_all['rank'].min(), df_all['rank'].max(), 100)\n    fitted_curve = alpha + beta * rank_grid + gamma * rank_grid**2\n\n    # 시각화\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(8, 5))\n    ax.scatter(df_all['rank'], df_all['capshare'], alpha=0.4, label='Observed', color='steelblue')\n    ax.plot(rank_grid, fitted_curve, color='darkgreen', linewidth=2.5, label='Quadratic Fit')\n    ax.set_title(f\"Quadratic Fit (state={state}, n={n})\")\n    ax.set_xlabel(\"Rank\")\n    ax.set_ylabel(\"Capital Share\")\n    ax.legend()\n    ax.grid(True)\n\n    return \n\ndef plot_exponential_fit(df_in_sample, n=10, state=10, ax=None):\n    \"\"\"\n    특정 in-sample에서 주어진 state, top-n 종목에 대한\n    (rank, capshare) 산점도와 exponential regression fitted line 시각화\n    \"\"\"\n\n    all_obs = []\n\n    for date, group in df_in_sample[df_in_sample['state'] == state].groupby('date'):\n        group = group.sort_values('mktcap_lag', ascending=False).head(n).copy()\n        if len(group) < n:\n            continue\n\n        group = group.sort_values('mktcap_lag')  # 작은 순서대로 재정렬\n        group['rank'] = np.arange(1, len(group) + 1)\n        total_cap = group['mktcap_lag'].sum()\n        group['capshare'] = group['mktcap_lag'] / total_cap\n\n        all_obs.append(group[['rank', 'capshare']])\n\n    if not all_obs:\n        raise ValueError(\"No valid observations for fitting.\")\n\n    df_all = pd.concat(all_obs, ignore_index=True)\n    df_all['log_capshare'] = np.log(df_all['capshare'])\n\n    # 회귀\n    X = sm.add_constant(df_all['rank'])\n    y = df_all['log_capshare']\n    model = sm.OLS(y, X).fit()\n\n    # 추정 계수\n    ln_alpha, beta = model.params\n    alpha = np.exp(ln_alpha)\n\n    # Fitted curve\n    rank_grid = np.linspace(df_all['rank'].min(), df_all['rank'].max(), 100)\n    fitted_curve = alpha * np.exp(beta * rank_grid)\n\n    # 시각화\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(8, 5))\n    ax.scatter(df_all['rank'], df_all['capshare'], alpha=0.4, label='Observed', color='steelblue')\n    ax.plot(rank_grid, fitted_curve, color='darkred', linewidth=2.5, label='Exponential Fit')\n    ax.set_title(f\"Exponential Fit (state={state}, n={n})\")\n    ax.set_xlabel(\"Rank\")\n    ax.set_ylabel(\"Capital Share\")\n    ax.legend()\n    ax.grid(True)\n\n    return \n```\n\n#### Empirical Fit of Capital Share Functions\n\nTo empirically validate the structural weighting functions, we fit both quadratic and exponential models to the in-sample relationship between rank and capital share. The following plots show the cross-sectional fitting results based on a representative rebalance date.\n\n\n```{python}\ndef split_in_out_sample(df, in_end, in_sample_months=36, out_end=None):\n    \"\"\"\n    주어진 in_end와 in_sample_months, 그리고 선택적으로 out_end를 이용해 \n    in-sample과 out-of-sample 데이터를 분할합니다.\n    \n    Parameters:\n      - df: 전체 데이터프레임 (반드시 'date' 컬럼이 있어야 함)\n      - in_end: in-sample 종료일 (string 또는 datetime)\n      - in_sample_months: in-sample 기간 (월 단위, default 36)\n      - out_end: out-of-sample 종료일 (string 또는 datetime). None인 경우 in_end 이후 전체가 out-of-sample.\n    \n    Returns:\n      - in_sample: [in_end - in_sample_months, in_end] 기간의 데이터프레임\n      - out_sample: (in_end, out_end] 또는 in_end 이후 전체 데이터프레임\n    \"\"\"\n    df = df.copy()\n    df['date'] = pd.to_datetime(df['date'])\n    in_end = pd.to_datetime(in_end)\n    \n    # in-sample 기간 계산\n    in_start = in_end - pd.DateOffset(months=in_sample_months)\n    in_sample = df[(df['date'] >= in_start) & (df['date'] <= in_end)].copy()\n    \n    # out-of-sample 기간 계산\n    if out_end is not None:\n        out_end = pd.to_datetime(out_end)\n        out_sample = df[(df['date'] > in_end) & (df['date'] <= out_end)].copy()\n    else:\n        out_sample = df[df['date'] > in_end].copy()\n    \n    return in_sample, out_sample\n```\n\n```{python}\nin_end = '2009-12-31'\nin_sample_months = 48\n\nprint('Snapshot at:', in_end)\nprint('Look-back period:', in_sample_months, 'months')\n\ndf_in_sample, _ = split_in_out_sample(crsp, in_end, in_sample_months)\n```\n\n```{python}\n#| fig-cap: \"Quadratic vs. Exponential Fit at 2009-12-31\"\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nplot_quadratic_fit(df_in_sample, n=10, state=10, ax=axes[0])\nplot_exponential_fit(df_in_sample, n=10, state=10, ax=axes[1])\n\nfig.suptitle(f\"Fitted Capital Share Functions at {in_end}\")\nplt.tight_layout()\n```\n\n```{python}\nin_end = '2023-12-31'\nin_sample_months = 48\n\nprint('Snapshot at:', in_end)\nprint('Look-back period:', in_sample_months, 'months')\n\ndf_in_sample, _ = split_in_out_sample(crsp, in_end, in_sample_months)\n```\n\n```{python}\n#| fig-cap: \"Quadratic vs. Exponential Fit at 2023-12-31\"\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nplot_quadratic_fit(df_in_sample, n=10, state=10, ax=axes[0])\nplot_exponential_fit(df_in_sample, n=10, state=10, ax=axes[1])\n\nfig.suptitle(f\"Fitted Capital Share Functions at {in_end}\")\nplt.tight_layout()\n```\n\nThese cross-sectional plots confirm the superiority of the exponential fit in capturing the accelerating concentration of capital among top-ranked firms. The difference is especially pronounced in the post-2010 sample, reflecting a structural shift in capital dynamics during the QE era.\n\nThe exponential fit exhibits stronger monotonicity and structural convexity, particularly in the top-ranked firms, supporting its use in the TBTF weighting scheme.\n\n\n### Rebalancing Frequency\n\nWe test fixed-interval rebalancing schemes:\n\n- Monthly (default)\n- Quarterly\n- Semiannual\n- Annual\n\nRebalancing frequency directly affects turnover and transaction cost implications. Monthly rebalancing is selected as the baseline to balance responsiveness with frictions.\n\n\n### Benchmark Portfolios\n\nFor external comparison, we use:\n\n- **Pre-2010 Index Benchmarks**: Dow Jones Industrial Average (^DJI), Nasdaq-100 (^NDX)\n- **Post-2010 Index ETFs**: \n  - DIA (ETF version of DJIA, State Street Corporation ETF. Fund inception: 1998/01/14), \n  - QQQ (ETF version of NDX. Nasdaq-100 ticker. the Invesco QQQ Trust. Fund inception: 1999/03/10), \n  - SPY (The SPDR S&P 500 ETF, Fund inception: 1993/01/22), \n  - VTI (Vanguard Total Stock Market ETF, Fund inception: 2001년 5월 24일), \n- **Post-2010 Style Portfolios**: Fama-French ME5 × PRIOR1/3/5, constructed with rolling monthly value- or equal-weighting\n\n\n### Strategic Rationale\n\nThe TBTF strategy is not merely a rule-based selection method. It reflects a structural argument that allocative efficiency in modern markets is compromised by persistent capital concentration. Instead of diversifying away idiosyncratic risk, markets are increasingly dominated by capital lock-in, hierarchy reinforcement, and narrative legitimacy.\n\nThis framework reconceptualizes the role of financial assets from carriers of risk to vehicles of structural dominance, and evaluates portfolio construction in light of this altered paradigm.\n\n\n## Appendix: TBTF Strategy Pipeline {.appendix}\n\nThis section outlines the modular structure of the TBTF portfolio strategy, from input specification to out-of-sample return generation and performance evaluation. The pipeline is designed to be flexible across different weighting schemes, rebalance frequencies, and strategy parameters.\n\n### Inputs (Arguments)\n\n| Argument | Description |\n|----------|-------------|\n| `df` | Main input DataFrame (`crsp`) including fields such as `date`, `permno`, `mktcap`, `ret`, `state`, `mktcap_lag`, etc. |\n| `state_level` | Target capital state to define the asset universe, typically the top decile (e.g., `10`). |\n| `top_n` | Number of assets to be selected at each rebalance point (e.g., `n ∈ {5, 10, 20, 30, 50}`). |\n| `rebalance_freq` | Rebalancing interval (e.g., `'1M'`, `'3M'`, `'6M'`, `'12M'`). |\n| `weighting_method` | One of `'equal'`, `'value'`, `'quadratic'`, or `'exponential'`. |\n| `in_sample_period` | Estimation window for in-sample weight calibration (e.g., `'2010-01-01'` to `'2013-12-31'`). |\n| `out_sample_period` | Evaluation window for out-of-sample backtesting (e.g., `'2014-01-01'` to `'2023-12-31'`). |\n| `eta`, `p` | Parameters for CRRA utility (`eta`) and Omega ratio threshold (`p`). |\n\n\n### Strategy Pipeline (Pseudo-code Logic)\n\n#### Step 1: Data Partitioning & Filtering\n\n```python\nin_sample = df[(df['date'] >= in_sample_start) & (df['date'] <= in_sample_end)]\nout_sample = df[(df['date'] > in_sample_end) & (df['date'] <= out_sample_end)]\nuniverse = df[df['state'] == state_level]\n```\n\n- Restrict selection universe to target capital state (e.g., top decile).\n\n\n#### Step 2: In-sample Weight Estimation\n\nIf `weighting_method` is `'quadratic'` or `'exponential'`:\n\n- Estimate the relationship between within-state rank and capital share using in-sample data:\n  - Quadratic:  \n    $$\\text{CapShare}_i = \\alpha + \\beta \\cdot \\text{Rank}_i + \\gamma \\cdot \\text{Rank}_i^2$$\n  - Exponential:  \n    $$\\text{CapShare}_i = \\alpha \\cdot e^{\\beta \\cdot \\text{Rank}_i}$$\n- Save estimated coefficients:\n  ```python\n  coefficients = {'alpha': ..., 'beta': ..., 'gamma': ...}\n  ```\n\n#### Step 3: Out-of-sample Portfolio Construction\n\nFor each rebalance date in the out-sample period:\n\n1. Filter to target state (`state == state_level`)\n2. Rank by market cap, select top `n`\n3. Assign weights:\n   - Equal: $w_i = 1/n$\n   - Value: $w_i = \\text{mktcap}_i / \\sum \\text{mktcap}$\n   - Quadratic: apply $\\hat{\\alpha}, \\hat{\\beta}, \\hat{\\gamma}$ to rank\n   - Exponential: apply $\\hat{\\alpha}, \\hat{\\beta}$ to rank\n4. Store `[date, permno, weight]` for forward return application\n\n\n#### Step 4: Portfolio Return Computation\n\nAt each evaluation date after rebalance:\n\n- Merge forward returns of selected assets\n- Compute portfolio return:\n  $$R_t^{\\text{portfolio}} = \\sum_i w_{i,t} \\cdot r_{i,t}$$\n- Construct time series of out-of-sample portfolio returns\n\n\n#### Step 5: Turnover Calculation\n\nFor each rebalance window:\n\n- Calculate:\n  $$\\text{Turnover}_t = \\sum_i |w_{i,t} - w_{i,t-1}|$$\n- Useful for assessing transaction costs and liquidity requirements\n\n\n#### Step 6: Performance Evaluation\n\nUsing out-of-sample return series, compute:\n\n- **Risk-Adjusted Metrics**:\n  - Sharpe ratio, Sortino ratio\n  - Omega ratio (threshold = `p`)\n  - Calmar ratio, maximum drawdown (MDD)\n  - CRRA utility with risk aversion parameter `eta`\n\n- Return summary as dictionary:\n  ```python\n  metrics_dict = {\n      'Sharpe': ...,\n      'Sortino': ...,\n      'Omega': ...,\n      'CRRA': ...,\n      'CAGR': ...,\n      'MDD': ...\n  }\n  ```\n\n\n### Outputs\n\n| Output | Description |\n|--------|-------------|\n| `returns_df` | Time series of out-of-sample portfolio returns |\n| `weights_df` | Portfolio composition (weights per date and permno) |\n| `turnover_df` | Time series of turnover at each rebalance point |\n| `metrics_dict` | Dictionary of strategy performance metrics |\n\n### Module Lits\n\n```python\n#| label: TBTF Strategy Full Module\n#| warning: false\n#| message: false\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import skew, kurtosis\n\n# ----------------------------\n# 1. Data Partitioning\n# ----------------------------\ndef split_in_out_sample(df, in_end, in_sample_months=36, out_end=None):\n    in_sample = df[(df['date'] <= in_end)].copy()\n    if out_end:\n        out_sample = df[(df['date'] > in_end) & (df['date'] <= out_end)].copy()\n    else:\n        out_sample = df[(df['date'] > in_end)].copy()\n    return in_sample, out_sample\n\n# ----------------------------\n# 2. Weight Estimation\n# ----------------------------\ndef estimate_exponential_weights(df_in_sample, n=10, state=10):\n    df = df_in_sample[df_in_sample['state'] == state].copy()\n    df['rank'] = df.groupby('date')['mktcap'].rank(ascending=True, method='first')\n    df = df[df['rank'] <= n]\n    df['log_capshare'] = np.log(df['mktcap'] / df.groupby('date')['mktcap'].transform('sum'))\n    X = df[['rank']]\n    X = sm.add_constant(X)\n    y = df['log_capshare']\n    model = sm.OLS(y, X).fit()\n    return {'alpha': np.exp(model.params['const']), 'beta': model.params['rank']}\n\ndef estimate_quadratic_weights(df_in_sample, n=10, state=10):\n    df = df_in_sample[df_in_sample['state'] == state].copy()\n    df['rank'] = df.groupby('date')['mktcap'].rank(ascending=True, method='first')\n    df = df[df['rank'] <= n]\n    df['capshare'] = df['mktcap'] / df.groupby('date')['mktcap'].transform('sum')\n    df['rank_sq'] = df['rank'] ** 2\n    X = df[['rank', 'rank_sq']]\n    X = sm.add_constant(X)\n    y = df['capshare']\n    model = sm.OLS(y, X).fit()\n    return {'alpha': model.params['const'], 'beta': model.params['rank'], 'gamma': model.params['rank_sq']}\n\n# ----------------------------\n# 3. Portfolio Construction\n# ----------------------------\ndef construct_tbtf_exponential(crsp_df, target_state, top_n, params):\n    df = crsp_df[crsp_df['state'] == target_state].copy()\n    df['rank'] = df.groupby('date')['mktcap'].rank(ascending=True, method='first')\n    df = df[df['rank'] <= top_n]\n    df['weight'] = params['alpha'] * np.exp(params['beta'] * df['rank'])\n    df['weight'] = df['weight'] / df.groupby('date')['weight'].transform('sum')\n    return df[['date', 'permno', 'weight']]\n\ndef construct_tbtf_quadratic(crsp_df, target_state, top_n, params):\n    df = crsp_df[crsp_df['state'] == target_state].copy()\n    df['rank'] = df.groupby('date')['mktcap'].rank(ascending=True, method='first')\n    df = df[df['rank'] <= top_n]\n    df['rank_sq'] = df['rank'] ** 2\n    df['weight'] = params['alpha'] + params['beta'] * df['rank'] + params['gamma'] * df['rank_sq']\n    df['weight'] = df['weight'] / df.groupby('date')['weight'].transform('sum')\n    return df[['date', 'permno', 'weight']]\n\n# ----------------------------\n# 4. Return and Turnover Calculation\n# ----------------------------\ndef compute_return_tbtf(crsp, rebalance_dates, weighting_method='exponential', top_n=10, state=10, in_sample_months=36):\n    # Placeholder for full implementation\n    pass\n\ndef compute_return_pfo(crsp, rebalance_dates, weighting_method='vw', top_n=10):\n    # Placeholder for traditional VW or EW method\n    pass\n\ndef compute_turnover(weights_df, rebalance_dates):\n    turnover_list = []\n    prev_weights = None\n    for date in rebalance_dates:\n        w = weights_df[weights_df['date'] == date].set_index('permno')['weight']\n        if prev_weights is not None:\n            turnover = (w - prev_weights).abs().sum()\n            turnover_list.append({'date': date, 'turnover': turnover})\n        prev_weights = w\n    return pd.DataFrame(turnover_list)\n\n# ----------------------------\n# 5. Performance Evaluation\n# ----------------------------\ndef evaluate_performance(returns, eta=3, p=0.01, periods_per_year=12):\n    mu = returns.mean() * periods_per_year\n    sigma = returns.std() * np.sqrt(periods_per_year)\n    sharpe = mu / sigma if sigma != 0 else np.nan\n    sortino = mu / returns[returns < 0].std() if returns[returns < 0].std() != 0 else np.nan\n    omega = (returns[returns > p] - p).sum() / abs((returns[returns <= p] - p).sum())\n    crra_utility = (1 / (1 - eta)) * (1 + returns).apply(lambda x: x**(1 - eta) - 1).mean() if eta != 1 else np.log(1 + returns).mean()\n    return {\n        'Sharpe': sharpe,\n        'Sortino': sortino,\n        'Omega': omega,\n        'CRRA': crra_utility,\n        'Mean': mu,\n        'Volatility': sigma\n    }\n\n# ----------------------------\n# 6. Rebalance Date Utility\n# ----------------------------\ndef get_rebalance_offset(rebalance_freq):\n    offset_map = {'1M': 1, '3M': 3, '6M': 6, '12M': 12}\n    return offset_map.get(rebalance_freq, 1)\n\n# ----------------------------\n# 7. Backtest Pipeline\n# ----------------------------\ndef backtest_pipeline(crsp, in_end, out_end, in_sample_months, rebalance_freq, weighting_method, top_n, state, eta, p):\n    # Placeholder for full backtest execution logic\n    pass\n\n# ----------------------------\n# 8. Visualization (optional)\n# ----------------------------\ndef plot_quadratic_fit(df_in_sample, n=10, state=10):\n    # Placeholder for plot generation\n    pass\n\ndef plot_exponential_fit(df_in_sample, n=10, state=10):\n    # Placeholder for plot generation\n    pass\n\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"number-sections":true,"output-file":"4_5_strategy.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","author":"gitSAM","date":"2025-03-31","bibliography":["references.bib"],"jupyter":"python3","theme":"cosmo","title":"05 Strategy"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}