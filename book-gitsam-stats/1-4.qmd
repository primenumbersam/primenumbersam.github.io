---
title: 부록-무작위 표본추출법 (Random Sampling)
---
통계학은 불확실성을 다루는 학문입니다. 그러나 이 불확실성이 무질서함을 의미하지는 않습니다. 통계적 추론은 매우 엄격한 수학적 조건과 철학적 전제를 필요로 하며, 그 출발점은 표본을 어떻게 추출하느냐에 있습니다. 무작위 표본추출(random sampling)은 표본이 모집단의 특성을 왜곡 없이 반영하도록 보장하는 가장 기본적인 원칙입니다.

## 무작위성과 독립성의 개념

무작위 표본추출이란, 모집단의 각 요소가 **동일한 확률로 선택될 기회를 가지며**, 그 선택이 **서로 독립적**으로 이루어지는 과정을 말합니다. 여기서 ‘동일한 확률’만큼이나 중요한 것이 ‘독립성(independence)’입니다. 표본들 간의 추출 결과가 서로 영향을 미치지 않아야 모집단의 구조를 정확히 반영할 수 있습니다.

예를 들어, 어떤 설문조사에서 첫 번째로 추출된 응답자의 특성이 두 번째 응답자 선정에 영향을 준다면, 이 표본은 더 이상 독립적으로 추출되었다고 볼 수 없습니다. 이러한 경우, 표본 사이의 상관관계로 인해 정보가 중복되거나 편향이 발생하게 됩니다. 이는 추정치의 분산을 과소평가하게 만들며, 결과적으로 신뢰구간이나 통계적 검정의 타당성이 크게 훼손됩니다.

통계학은 이러한 독립성을 다음의 수학적 관계로 표현합니다: $P(A \cap B) = P(A) \cdot P(B)$
이 조건은 사건 $A$와 $B$가 서로 독립일 때의 곱셈 법칙이며, 무작위 추출된 표본들 간에도 동일하게 적용됩니다.

## 무작위 수를 이용한 파이 값 추정

무작위성과 확률 개념은 단지 철학적 원리에 그치지 않고, 수치 계산에도 직접 응용됩니다. 대표적인 예로 **몬테카를로(Monte Carlo) 방법**을 이용한 원주율 $\pi$ 근사 계산이 있습니다.

단위 정사각형 안에 반지름 1인 사분원을 그려 놓고, 그 안에 무작위로 점을 뿌려서 이 점이 원 안에 들어갈 확률을 계산하면, 전체 면적의 비율을 통해 $\pi$를 근사할 수 있습니다. 이때 계산 공식은 다음과 같습니다: $\pi \approx 4 \times \frac{\text{원이 포함된 점의 수}}{\text{총 점의 수}}$

이 방법은 무작위로 생성된 점들이 독립적으로 분포되어 있다는 전제 하에서만 유효합니다. 무작위성과 독립성은 계산의 정확성을 보장하는 핵심 전제입니다.

## 이항분포와 부트스트랩의 구조

통계학에서 자주 등장하는 **이항분포**도 무작위성과 독립성을 전제로 구성됩니다. 성공 확률이 $p$인 시행을 $n$번 반복할 때, 성공 횟수는 이항분포를 따르게 됩니다. 각 시행이 독립적으로 이루어졌다는 전제는 이 분포의 핵심 구성 요소입니다.

이와 유사한 개념은 **부트스트랩(bootstrap)** 방법에서도 확인할 수 있습니다. 부트스트랩은 하나의 표본에서 복원추출을 반복하여 여러 개의 재표본을 구성하고, 이를 통해 통계량의 분포를 추정하는 방법입니다. 이때 각 추출이 독립적으로 이루어지는 것이 전제되어야 하며, 이러한 구조 아래에서 **중심극한정리**가 적용되고 신뢰구간을 설정할 수 있습니다[^1]

## 신뢰구간과 대표성 문제

통계학에서 자주 사용되는 **신뢰구간(confidence interval)** 개념 역시 무작위성과 독립성을 전제로 합니다. 동일한 방식으로 95% 신뢰구간을 구성하고 이를 여러 번 반복하면, 약 95%의 경우에 해당 구간이 실제 모수를 포함하게 됩니다. 그러나 이 해석은 표본이 올바르게 무작위로, 그리고 독립적으로 추출되었을 때만 성립합니다.

예를 들어 특정 후보의 지지율을 조사하면서 그 후보의 지지층이 많은 지역만을 표본으로 삼는다면, 이는 **오버샘플링(over-sampling)** 문제를 유발하며 통계적 추론은 왜곡될 수밖에 없습니다. **표본의 대표성**은 단순히 표본의 수가 많은 것으로 보장되지 않으며, 무작위성과 독립성이 확보되었는지 여부에 따라 결정됩니다.

## 난수 발생과 역변환법

컴퓨터 시뮬레이션에서는 무작위 수, 즉 난수를 생성하는 방법이 필수적입니다. 일반적으로는 $[0,1]$ 구간에서 균등한 확률로 생성된 난수 $U$를 사용하며, 이를 원하는 분포의 확률변수로 변환하기 위해 **역변환법(inverse transform method)**이 사용됩니다.

확률분포 $F(x)$에 대해 누적분포함수 $F$의 역함수를 취하면, 다음과 같은 방식으로 새로운 확률변수를 정의할 수 있습니다: $X = F^{-1}(U)$

이 방식은 간단하면서도 다양한 분포에 적용이 가능하며, 난수의 구조가 이론적으로 잘 정의되어 있을 때 특히 효과적입니다[^2].

## 마르코프 체인과 MCMC 방식

더 복잡한 확률분포에서 표본을 추출하려면 **마르코프 체인 몬테카를로(MCMC)** 방식이 사용됩니다. 이 방식은 표본 간의 독립성을 전제로 하지 않지만, 장기적으로 특정 분포에 수렴하도록 설계된 확률적 과정입니다.

MCMC는 **마르코프 체인(Markov Chain)**을 기반으로 하며, 현재 상태만이 다음 상태를 결정하는 확률적 규칙에 따라 새로운 표본을 생성합니다. 이러한 상태 전이가 충분히 반복되면, 체인은 하나의 **스테이셔너리 분포(stationary distribution)**에 수렴하게 됩니다. 이 상태에서는 더 이상 분포가 변화하지 않으며, 이 분포는 타겟 분포로 간주할 수 있습니다[^3].

## 메트로폴리스–헤이스팅스 알고리즘

MCMC 기법 중 대표적인 알고리즘은 **메트로폴리스–헤이스팅스(Metropolis–Hastings)** 방법입니다. 이 방법은 우리가 직접 샘플링할 수 없는 복잡한 분포에서 샘플을 생성하기 위해, 비교적 단순한 **제안 분포(proposal distribution)**를 사용합니다.

새로운 상태 $x'$이 제안되면, 기존 상태 $x$와의 상대적인 가능성을 평가하는 **수용 확률(acceptance probability)**을 통해 그 상태를 채택하거나 유지합니다. 수용 확률은 다음과 같이 계산됩니다:
$$\alpha = \min\left(1, \frac{p(x') q(x|x')}{p(x) q(x'|x)}\right)$$

이 방식을 사용하면, 타겟 분포 $p(x)$가 정규화 상수를 알 수 없는 경우에도 효과적으로 샘플링할 수 있습니다[^4].

[^1]: 중심극한정리(Central Limit Theorem)는 독립이고 동일분포를 따르는 확률변수들의 합이 정규분포로 수렴한다는 정리입니다. 

[^2]:역변환법은 $X \sim F$를 얻기 위해 $X = F^{-1}(U)$를 계산하는 방식입니다. $U$는 $[0,1]$에서 균등하게 추출된 난수입니다. 

[^3]:스테이셔너리 분포란 확률분포 $\pi$가 상태 전이행렬 $P$에 대해 $\pi P = \pi$를 만족하는 경우를 의미합니다. 

[^4]:메트로폴리스–헤이스팅스 알고리즘은 복잡한 분포에서 직접 샘플링이 어려울 때, 수용확률을 계산하여 효율적으로 근사 샘플을 생성하는 MCMC 기법입니다.