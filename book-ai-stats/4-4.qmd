---
title: 통계적 학습 (Statistical Learning)
---
## 통계적 학습 개요

통계적 학습(Statistical Learning)은 데이터로부터 **패턴을 학습하여 예측이나 설명을 수행하는 알고리즘적 절차**를 의미합니다. 

|학습 방식|입력|출력|목적|예시|
|---|---|---|---|---|
|지도 학습|$X$|$Y$|예측|가격 예측, 분류|
|비지도 학습|$X$|없음|구조 파악|클러스터링, PCA|
|강화 학습|상태, 행동|보상|정책 최적화|게임 AI, 로봇|

## 지도 학습 (Supervised Learning)

- 지도 학습은 **입력 벡터 $X$와 대응하는 출력 $Y$ 간의 함수적 관계를 추정**하는 문제입니다.
- 예: 특정 특성을 가진 개인이 상품을 구매했는지 ($Y = 1$), 구매하지 않았는지 ($Y = 0$) **예측**
- 입력 특성 ($X$): 나이, 지역, 교육 수준, 성별 등

### 회귀분석 (선형/로지스틱 회귀)

### 결정트리 (Decision Tree)

- 데이터의 특성을 기준으로 이진 분할하여 예측을 수행하는 구조화된 모델
- 해석 가능성이 높으나 과적합 위험 존재
- **랜덤 포레스트 (Random Forest)**: 
    - 여러 개의 결정트리를 앙상블하여 예측 안정성을 확보. 
    - **무작위 변수 선택 + 배깅(Bagging)**을 통해 과적합 완화. 
    - 비선형적인 데이터 분류 및 회귀에 강건

### SVM (Support Vector Machine)

### 신경망 모형(Neural Network Model)

## 비지도 학습 (Unsupervised Learning)

- 정답 없이 주어진 데이터 $X$로부터 **군집 구조, 차원 축소, 밀도 추정** 등을 수행합니다.
- 목표는 **데이터의 패턴이나 구조적 특징을 파악하는 것**입니다.

### 주성분 분석 (Principal Component Analysis, PCA)

- **목적**: 고차원의 데이터를 **정보 손실을 최소화하면서 저차원으로 축소**
- **방법**:
    - $p$개의 특성을 선형 결합하여 새로운 축(주성분)을 생성
    - 분산이 가장 큰 방향을 기준으로 차원 선택
- **수식적 정의**: 주성분 $Z_1 = a_1^\top X$는 $\text{Var}(Z_1)$을 최대화하는 $a_1$을 찾는 문제
    
### 군집 분석 (Clustering)

- **정의**: 유사한 관측치를 하나의 군집으로 묶는 방법
- **기본 원칙**:
    - **군집 간 이질성**: 서로 다른 군집은 명확히 구분되어야 함
    - **군집 내 동질성**: 같은 군집 내 관측치는 유사해야 함
- (1) K-평균 알고리즘
	- 초기 중심 $k$개 설정 → 각 데이터에 가장 가까운 중심 할당 → 중심 재계산 → 반복
	- 초기값 의존성 있음 → 여러 초기값으로 반복 시도
- (2) 계층적 클러스터링
	- 각 데이터를 클러스터로 시작 → 가장 가까운 쌍을 반복적으로 병합
	- dendrogram으로 시각화 가능
- (3) 거리 측정 방법
	- 최소 거리 (single linkage)
	- 최대 거리 (complete linkage)
	- 평균 거리 (average linkage)

## 강화 학습 (Reinforcement Learning)

- 학습자는 환경과 상호작용하며 **행동(action)에 대한 보상(reward)**을 통해 최적 정책을 학습합니다.
- 보상은 지연되어 주어질 수 있으며, 장기적 기대보상을 극대화하는 방향으로 학습이 진행됩니다.
- Carrot & Stick: 올바른 행동에 보상, 잘못된 행동에 벌칙
- 알파고: 수천 번의 게임을 반복하며 승리 확률을 극대화하는 전략을 학습