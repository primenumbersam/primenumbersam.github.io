[
  {
    "objectID": "projects/pricing_equal/pricing_equal.html",
    "href": "projects/pricing_equal/pricing_equal.html",
    "title": "Pricing the seemingly Equal Opportunities under Structural Inequality",
    "section": "",
    "text": "By applying the EMM-based asset pricing approach, this study quantifies the impact of structural inequalities on the valuation of ostensibly equal opportunities. The results emphasize the importance of considering underlying economic disparities when evaluating the fairness and effectiveness of qualification standards in society."
  },
  {
    "objectID": "projects/pricing_equal/pricing_equal.html#conclusion",
    "href": "projects/pricing_equal/pricing_equal.html#conclusion",
    "title": "Pricing the seemingly Equal Opportunities under Structural Inequality",
    "section": "",
    "text": "By applying the EMM-based asset pricing approach, this study quantifies the impact of structural inequalities on the valuation of ostensibly equal opportunities. The results emphasize the importance of considering underlying economic disparities when evaluating the fairness and effectiveness of qualification standards in society."
  },
  {
    "objectID": "projects/pricing_equal/pricing_equal.html#main",
    "href": "projects/pricing_equal/pricing_equal.html#main",
    "title": "Pricing the seemingly Equal Opportunities under Structural Inequality",
    "section": "Main",
    "text": "Main\n\nModel Scenario\nIn short, we consider a society divided into two distinct classes:\n\nProletariat (P): Individuals with access to general opportunities.\nCapitalist (C): Individuals with access to both general and exclusive special opportunities.\n\nInternally, both classes operate within perfectly competitive markets that adhere to the no-arbitrage principle. However, due to capital constraints, members of the P class cannot access the special opportunities available to the C class, rendering these opportunities unattainable. Consequently, while the absolute value of special opportunities is equal to or greater than that of general opportunities, the P class cannot exploit potential arbitrage opportunities due to these constraints. Both classes have offspring who inherit the economic outcomes of their parents’ investments. To claim these inherited assets, all offspring must meet a minimum qualification standard (e.g., educational credentials), analogous to the strike price (\\(K\\)) in option pricing. Until this qualification is met, the offspring hold a call option on their parents’ assets.\nIn detail, consider two distinct social classes: the proletariat (P), representing working-class individuals, and the capitalist class (C), representing wealthy individuals. These two classes face fundamentally different opportunity sets due to deep-seated structural inequalities. Such societal barriers, from both democratic and utilitarian viewpoints, constitute a significant social inefficiency.\nTo analyze the structural origins of this inefficiency, we apply the concept of Limits to Arbitrage Theory, which suggests markets are not always fully efficient. This inefficiency arises because of various constraints, such as behavioral biases, risk constraints, and notably, capital constraints. Capital constraints imply that significant capital is required to engage in arbitrage, effectively isolating classes economically. We assume, therefore, that the proletariat and capitalist classes are economically segregated due to these capital constraints.\nWithin each class, economic opportunities exist in a perfectly competitive market, satisfying the no-arbitrage condition internally. Members of the proletariat (P) freely select from a common set of general opportunities available to them. Conversely, members of the capitalist class (C) not only share these general opportunities but also exclusively access additional “special opportunities.” From the viewpoint of proletariat class members, these special opportunities represent unattainable benefits (“grapes beyond reach”), carrying higher or equal absolute value compared to general opportunities.\nTheoretically, if members of the capitalist class could short-sell general opportunities and simultaneously long-position special opportunities, they could realize arbitrage profits. However, due to aforementioned capital constraints (“limits to arbitrage”), such arbitrage trading is practically impossible within this model.\nBoth classes have offspring who inherit the economic results (absolute asset values) of their parents’ investment choices. To claim these inherited assets, children from both classes must meet identical minimum qualification standards (e.g., university diplomas, basic educational credentials). Although the qualification standard is identical for both, outcomes differ significantly due to inherited assets. For instance, a business administration graduate from the capitalist class inherits and manages substantial capital (businesses), while an identically qualified individual from the proletariat class works as an employee, earning wages in capitalist-owned enterprises.\nThe minimum qualification standard can be understood as a fixed barrier or strike price (K) of a call option. Until the qualification requirement is fulfilled, the children effectively hold call options on their parents’ assets. This model aims to quantify the absolute value of these call options for each class, reflecting the inherited economic outcomes accessible to the offspring.\n\n\nEMM-based Call Option Valuation Theory\nAssume a simple 1 period setting with only two possible states (e.g. good or bad). Under the Equivalent Martingale Measure (EMM), the fair market value of a call option at time 0, denoted as \\(\\hat{f}_0\\), must satisfy:\n\\[\\hat{f_0}\\cdot R = E^q[f_1]\\] where \\(f_1=max(S_0 \\cdot U-K,0)\\)\n\\[S_0\\cdot R=E^q[S_1]\\] where \\(S_0\\) = the current price of risky underlying asset\nFrom these two equations, we have the EMM or the state price density for good state \\(q\\) as: \\[\nq = \\frac{R - D}{U - D}\n\\]\nThus, the present fair value of the call option is given by:\n\\[\n\\hat{f}_0 = \\frac{1}{R}\\left[ \\frac{R - D}{U - D}(S_0 \\cdot U - K) + \\frac{U - R}{U - D} \\cdot 0 \\right] = \\frac{(R - D)(U - 1)}{R(U - D)}\n\\]\nassuming that\n\nInitial Asset Price (normalized): \\(S_0=1\\)\n\nStrike Price (qualification threshold): \\(K=1\\)\n\nMaturity: 18 years (quarterly steps = 72 periods)\n\nThis formula indicates a clear proportional relationship for estimating current fair values representing inherited qualification-based claims for each class over a 18-year maturity period. While this valuation could be approximated using continuous distributions (e.g., Black-Scholes under symmetric assumptions \\(U \\cdot D=1\\)), our discrete binomial model allows straightforward interpretation without loss of economic intuition.\n\n\nEmpirical Analysis\nWe employ distinct underlying assets for each class. Using the historical dataset (Q1 1982–Q4 2019, 152 quarterly observations), we estimated the parameters and their associated fair values of call options for each class.\nFor Proletariat (P) Class Children:\n\nRisky Asset: US Median usual weekly Real earnings (LES1252881600Q)\n\nRisk-Free Asset: US Real GDP per capita (A939RX0Q048SBEA)\n\nParameters:\n\n\\(U_p\\):= 75th percentile growth of wage (risky asset)\n\n\\(D_p\\):= 25th percentile growth of wage\n\n\\(R_p\\):= Median growth rate of Real GDP per capita\n\n\nFor Capitalist (C) Class Children:\n\nRisky Asset: S&P 500 equity (SPX)\n\nRisk-Free Asset: US 10-Year Treasury Bond\nParameters:\n\n\\(U_c\\):= 75th percentile quarterly growth of the equity index\n\n\\(D_c\\):= 25th percentile quarterly growth of the equity index\n\n\\(R_c\\):= Median of quarterly US 10-Year Treasury Bond Yield (DGS10)\n\n\nEmpirical Results:\n\nFor Proletariat (P) class children, \\(\\hat{P}_0=?\\)\n\nFor Capitalist (C) class children, \\(\\hat{C}_0=?\\)\n\n\n\nCode\nimport yfinance as yf\nimport pandas_datareader.data as web\nimport pandas as pd\nimport numpy as np\n\n# 데이터 기간 설정\nstart_date = '1982-01-01'\nend_date = '2019-12-31'\n\n# S&P 500 데이터 가져오기\nsp500 = yf.download(\"^GSPC\", start=start_date, end=end_date, interval=\"1d\")\nsp500_q = sp500['Close'].resample('QE').last()  # 분기별 종가 데이터\n\n# FRED 데이터 가져오기\nus_median_weekly_earnings = web.DataReader('LES1252881600Q', 'fred', start_date, end_date)\nus_real_gdp_per_capita = web.DataReader('A939RX0Q048SBEA', 'fred', start_date, end_date)\nus_10yr_treasury_yield = web.DataReader('DGS10', 'fred', start_date, end_date)\n\n# 인덱스를 맞추기 위해 분기별로 재샘플링\nus_median_weekly_earnings = us_median_weekly_earnings.resample('QE').last()\nus_real_gdp_per_capita = us_real_gdp_per_capita.resample('QE').last()\nus_10yr_treasury_yield = us_10yr_treasury_yield.resample('QE').last()\n\n# 데이터프레임으로 변환\ndata = pd.DataFrame({\n    'SP500': sp500_q.squeeze(),\n    'Median_Weekly_Earnings': us_median_weekly_earnings['LES1252881600Q'].squeeze(),\n    'Real_GDP_per_Capita': us_real_gdp_per_capita['A939RX0Q048SBEA'].squeeze(),\n    '10yr_Treasury_Yield': us_10yr_treasury_yield['DGS10'].squeeze()\n}, index=sp500_q.index)\n\n# 결측값 제거\ndata.dropna(inplace=True)\n\n# 수익률 계산\ndata['SP500_Return'] = data['SP500'].pct_change()\ndata['Earnings_Growth'] = data['Median_Weekly_Earnings'].pct_change()\ndata['GDP_Growth'] = data['Real_GDP_per_Capita'].pct_change()\n\n# 통계치 계산\nU_p = data['Earnings_Growth'].quantile(0.75)+1\nD_p = data['Earnings_Growth'].quantile(0.25)+1\nR_p = data['GDP_Growth'].median()+1\n\nU_c = data['SP500_Return'].quantile(0.75)+1\nD_c = data['SP500_Return'].quantile(0.25)+1\nR_c = data['10yr_Treasury_Yield'].median()\nR_c = R_c / 100 +1\n\nprint(f\"Proletariat Class Children Parameters:\")\nprint(f\"U_p: {U_p:.2f}\")\nprint(f\"D_p: {D_p:.2f}\")\nprint(f\"R_p: {R_p:.2f}\")\n\nprint(f\"\\nCapitalist Class Children Parameters:\")\nprint(f\"U_c: {U_c:.2f}\")\nprint(f\"D_c: {D_c:.2f}\")\nprint(f\"R_c: {R_c:.2f}\")\n\n\n# Binomial Option Pricing Model\ndef binomial_option_pricing(K, S_0, T, U, D, R, dt):\n    \"\"\"\n    K: Strike price\n    S_0: Initial stock price\n    T: Time to maturity (in years)\n    U: Up factor\n    D: Down factor\n    R: Risk-free rate\n    dt: Number of steps for each year\n    \"\"\"\n    n = T*dt # Number of steps in the binomial tree\n    q = (R - D) / (U - D)\n\n    # Initialize option values at maturity\n    option_values = np.zeros((n + 1, 1))\n    for i in range(n + 1):\n        ST = S_0 * (U ** i) * (D ** (n - i))\n        option_values[i] = max(0, ST - K)\n\n    # Backward recursion for option values\n    for j in range(n - 1, -1, -1):\n        for i in range(j + 1):\n            option_values[i] = (q * option_values[i + 1] + (1 - q) * option_values[i]) / R\n\n    return option_values[0, 0]\n\n\n# Parameters\nK = 1  # Strike price\nS_0 = 1  # Initial stock price\nT = 18  # Time to maturity (18 years)\ndt = 4 # Number of steps for each year\n\n# Calculate option prices\noption_price_proletariat = binomial_option_pricing(K, S_0, T, U_p, D_p, R_p, dt)\noption_price_capitalist = binomial_option_pricing(K, S_0, T, U_c, D_c, R_c, dt)\n\nprint(f\"\\nFair price of Call Option, held by Proletariat Class Children:\\n {option_price_proletariat:.2f}\")\nprint(f\"Fair price of Call Option, held by Capitalist Class Children:\\n {option_price_capitalist:.2f}\")\n\n\nYF.download() has changed argument auto_adjust default to True\n\n\n[*********************100%***********************]  1 of 1 completed\n\n\nProletariat Class Children Parameters:\nU_p: 1.01\nD_p: 1.00\nR_p: 1.01\n\nCapitalist Class Children Parameters:\nU_c: 1.07\nD_c: 0.99\nR_c: 1.05\n\nFair price of Call Option, held by Proletariat Class Children:\n 0.30\nFair price of Call Option, held by Capitalist Class Children:\n 0.97\n\n\n\n\nDiscussion\nThis model clarifies the stark inequality underlying “ostensibly equal” qualification standards. Although formally identical, the call options’ absolute valuations significantly diverge, reflecting distinct economic inheritances accessible to each class. This disparity highlights structural inefficiencies and deep-rooted inequalities, persisting despite nominally identical qualification standards.\nUltimately, this analysis underscores how asset-based class differentiation profoundly impacts the perceived and realized absolute value of educational and economic opportunities, illuminating critical implications for economic policy, educational equity, and social justice frameworks."
  },
  {
    "objectID": "projects/pricing_equal/pricing_equal.html#introduction",
    "href": "projects/pricing_equal/pricing_equal.html#introduction",
    "title": "Pricing the seemingly Equal Opportunities under Structural Inequality",
    "section": "Introduction",
    "text": "Introduction\nIn societies characterized by pronounced economic stratification, opportunities presented as equal often yield disparate outcomes across different social strata. This disparity arises from inherent structural inefficiencies that restrict access to certain opportunities based on class. The Limits to Arbitrage Theory posits that market inefficiencies can persist due to various constraints, including capital limitations, preventing rational traders from correcting mispricings (Shleifer and Vishny 1997). This paper explores how such constraints contribute to the unequal valuation of opportunities between the proletariat (P) and capitalist (C) classes."
  },
  {
    "objectID": "projects/pricing_equal/pricing_equal.html#literature-review",
    "href": "projects/pricing_equal/pricing_equal.html#literature-review",
    "title": "Pricing the seemingly Equal Opportunities under Structural Inequality",
    "section": "Literature Review",
    "text": "Literature Review\nThe theoretical foundation relies primarily on the limits to arbitrage theory, initially articulated by Shleifer and Vishny (Shleifer and Vishny 1997). Their seminal work shows how market inefficiencies persist due to practical constraints, particularly capital constraints, restricting the ability of arbitrageurs to exploit and correct mispricings. These constraints arise from significant capital requirements that effectively segregate participants into distinct economic spheres, as emphasized by subsequent studies on financially constrained arbitrageurs (Gromb and Vayanos 2002; Xiong 2001).\nGeanakoplos’ research introduces the leverage cycle, which explains how fluctuations in leverage and capital availability perpetuate systemic inequality and financial instability (Geanakoplos 2010). Complementary studies, such as that by Gromb and Vayanos, also demonstrate the welfare implications of constrained arbitrageurs operating under capital limitations, further exacerbating persistent inequality (Gromb and Vayanos 2002). Moreover, Barberis and Thaler’s comprehensive survey on behavioral finance indicates how cognitive and behavioral constraints exacerbate market inefficiencies, reinforcing the structural barriers that differentiate economic outcomes across social strata (Barberis and Thaler 2003).\nExtending beyond purely financial contexts, sociological and economic research provides additional perspectives on structural inequalities and opportunity valuation. Bourdieu’s concept of social reproduction underscores how cultural capital perpetuates socioeconomic inequalities across generations (Bourdieu 1973). Recent empirical evidence by Stansbury (Stansbury 2024) and findings by the Social Mobility Commission (Social Mobility Commission 2023) further demonstrate how economic capital inherited through generations shapes differential outcomes, even when individuals ostensibly possess identical qualifications.\nChetty et al. provide compelling evidence linking parental economic conditions to children’s educational outcomes and future earnings, strongly supporting the relevance of inherited economic positions in determining opportunity valuations (Chetty et al. 2014). Similarly, Piketty’s influential book highlights the crucial role inherited wealth plays in perpetuating structural economic disparities, emphasizing the critical nature of capital inheritance in shaping individuals’ economic trajectories and their access to opportunities (Piketty 2014).\nPolicy implications regarding these structural inequalities and efforts to enhance social mobility have been explored extensively by institutions such as the OECD. Their analyses suggest policy frameworks that might alleviate the persistent inequalities discussed herein (OECD 2018). Reeves’ concept of the “glass floor” further illustrates how affluent socioeconomic backgrounds systematically maintain class advantages despite equal or even lesser merit-based qualifications (Reeves 2017).\nCollectively, these studies underline a coherent narrative: ostensibly equal opportunities often conceal significant disparities rooted in inherited structural inequalities, persistent capital constraints, and behavioral limitations to arbitrage. Our model complements this literature by quantitatively evaluating how these structural factors systematically influence the absolute value of identical qualification standards across distinct socioeconomic groups."
  },
  {
    "objectID": "projects/gilded_age/gilded_age.html",
    "href": "projects/gilded_age/gilded_age.html",
    "title": "The New Gilded Age",
    "section": "",
    "text": "The term ‘Gilded Age’ was originally coined by Mark Twain in his novel The Gilded Age: A Tale of Today (Twain and Warner 1873), describing an era characterized by rapid economic expansion, extreme wealth concentration, and political corruption. A similar dynamic is emerging today, where financial and technological elites dominate economic output while wealth inequality reaches historic highs (Piketty 2014). The late 19th century saw industrial monopolies like Standard Oil and U.S. Steel controlling markets; today, tech giants such as Amazon, Apple, and Google exhibit similar dominance (Zucman 2019).\nSimultaneously, the Federal Reserve’s response to financial instability, particularly through excessive monetary expansion, contrasts with past policy mistakes that led to severe economic contractions due to monetary shrinkage (Bernanke 2000). If current economic trends persist—marked by the increasing concentration of wealth, hyperinflation risks, and geopolitical tensions—then the U.S. may be heading toward another crisis akin to the 1929 stock market collapse (Kindleberger 1978)."
  },
  {
    "objectID": "projects/gilded_age/gilded_age.html#extreme-wealth-concentration-and-economic-disparities",
    "href": "projects/gilded_age/gilded_age.html#extreme-wealth-concentration-and-economic-disparities",
    "title": "The New Gilded Age",
    "section": "Extreme Wealth Concentration and Economic Disparities",
    "text": "Extreme Wealth Concentration and Economic Disparities\nIn the late 19th century, “Robber Barons” controlled vast industrial empires while working-class Americans suffered under exploitative labor conditions (Irwin 2017). Today, the economic landscape reflects a similar dynamic: the top 1% of Americans hold over 30% of total U.S. wealth, and financial markets remain dominated by a handful of institutional investors and corporations (Saez and Zucman 2020). If historical trends hold, wealth concentration at this level often precedes financial and political crises."
  },
  {
    "objectID": "projects/gilded_age/gilded_age.html#financial-market-distortions-due-to-federal-reserve-policies",
    "href": "projects/gilded_age/gilded_age.html#financial-market-distortions-due-to-federal-reserve-policies",
    "title": "The New Gilded Age",
    "section": "Financial Market Distortions Due to Federal Reserve Policies",
    "text": "Financial Market Distortions Due to Federal Reserve Policies\nHistorically, the Federal Reserve’s failure to manage monetary policy effectively has exacerbated financial downturns. During the Great Depression, the Fed allowed the money supply to contract, worsening deflation (Friedman and Schwartz 1993). Conversely, in the 2008 financial crisis, the Fed implemented massive QE programs to avoid liquidity shortages (Gopinath and Gourinchas 2020). If the Fed continues expanding the money supply unchecked while maintaining low interest rates, it could trigger runaway inflation or asset bubbles (Reinhart and Rogoff 2010)."
  },
  {
    "objectID": "projects/gilded_age/gilded_age.html#protectionist-policies-and-global-trade-disruptions",
    "href": "projects/gilded_age/gilded_age.html#protectionist-policies-and-global-trade-disruptions",
    "title": "The New Gilded Age",
    "section": "Protectionist Policies and Global Trade Disruptions",
    "text": "Protectionist Policies and Global Trade Disruptions\nIn response to financial instability, the U.S. may turn to protectionist measures similar to those seen in the early 20th century, such as the Smoot-Hawley Tariff Act (Irwin 2017). If the U.S. imposes broad tariffs on allies like Canada, Mexico, and the EU (excluding the UK), retaliatory tariffs could significantly reduce global trade, accelerating economic fragmentation (Acker 2020)."
  },
  {
    "objectID": "projects/gilded_age/gilded_age.html#capital-controls",
    "href": "projects/gilded_age/gilded_age.html#capital-controls",
    "title": "The New Gilded Age",
    "section": "Capital Controls",
    "text": "Capital Controls\nTo prevent capital flight, the U.S. government might implement capital controls, restricting the movement of funds outside the country (Dornbusch 1996). Such policies could initially stabilize domestic financial markets by preventing liquidity outflows, but they would ultimately deter foreign investment and reduce the credibility of the U.S. dollar (Prasad 2021). If capital controls are implemented alongside protectionist trade policies, the global financial system could realign, reducing reliance on the dollar (Eichengreen 2019)."
  },
  {
    "objectID": "projects/gilded_age/gilded_age.html#internal-conflict",
    "href": "projects/gilded_age/gilded_age.html#internal-conflict",
    "title": "The New Gilded Age",
    "section": "Internal Conflict",
    "text": "Internal Conflict\nWith increasing partisan division, the U.S. could experience state-led resistance against federal economic policies. Democratic-led states might oppose Republican federal mandates, leading to legal disputes over taxation, social policies, and trade regulations (Levitsky and Ziblatt 2018). In extreme cases, states like California could advocate for economic or political autonomy, mirroring secessionist movements of the 19th century, while Texas, despite its strong Republican leanings, might push for greater state sovereignty in response to federal overreach or shifting national policies (Acker 2020)."
  },
  {
    "objectID": "projects/gilded_age/gilded_age.html#u.s.-dollar-as-the-global-reserve-currency",
    "href": "projects/gilded_age/gilded_age.html#u.s.-dollar-as-the-global-reserve-currency",
    "title": "The New Gilded Age",
    "section": "U.S. Dollar as the Global Reserve Currency",
    "text": "U.S. Dollar as the Global Reserve Currency\nThe decline of the British pound post-World War II illustrates how global reserve currencies can lose dominance due to internal and external economic shifts (Eichengreen 2019). If U.S. political instability continues, central banks worldwide may accelerate diversification away from dollar holdings, increasing reliance on alternative financial networks such as BRICS payment systems, Bitcoin, and other emerging digital currencies. (Prasad 2021)."
  },
  {
    "objectID": "projects/correlation_crypto/correlation_crypto.html",
    "href": "projects/correlation_crypto/correlation_crypto.html",
    "title": "Correlation within Crypto-currencies",
    "section": "",
    "text": "Abstract: 2025년 3월 현재, 시가총액이 크거나 투자자들에게 인기가 많은 주요 암호화폐(popular cryptocurrencies)를 선정하여 지난 1년간의 상관관계를 분석하였다. 대부분의 암호화폐 투자자들은 이러한 주요 암호화폐에 집중적으로 투자하는 경향이 있다. 한편, 암호화폐 자산에 대한 투자자의 평균 투자 기간은 단기(short-term)로, 일반적으로 1개월에서 3개월 사이에 해당한다. 이에 따라 본 연구에서는 데이터의 관측 빈도(observation frequency)를 일간(daily) 단위로 설정하고, 30일, 60일, 90일의 롤링 윈도우(rolling window)를 적용하여 주요 암호화폐 수익률의 선형 상관계수(Pearson’s coefficient)를 분석하였다. 이러한 분석은 변동성 헤징(volatility hedging)을 고려한 분산 투자(diversified investment) 전략 수립에 도움이 될 수 있다. 예를 들어, 일정한 투자 금액(예: 1억 원)을 주요 암호화폐 자산군 내에서 어떻게 배분할지 결정하는 데 있어, 상관계수 분석 결과가 투자 비중 조정에 유용한 정보를 제공할 것으로 기대된다."
  },
  {
    "objectID": "projects/correlation_crypto/correlation_crypto.html#서론",
    "href": "projects/correlation_crypto/correlation_crypto.html#서론",
    "title": "Correlation within Crypto-currencies",
    "section": "서론",
    "text": "서론\n비트코인(BTC)의 가격 및 수익률은, 단기적으로 다음과 같은 관계를 보여왔다.\n\nNDX (나스닥 100 지수)와 강한 양의 상관관계 (Nasdaq 2024, 2023),\nDXY (미국 달러 지수)와 강한 음의 상관관계 (Coindesk 2023; Coinglass 2023). 만약 비트코인 가격이 달러 가격과 장기적으로도 반대 방향으로 움직인다면, 이는 비트코인이 인플레이션 헤지 자산으로 간주될 수도 있을 가능성을 나타낸다 (Dyhrberg 2021).\n금 가격 (GOLD), 국내 실질 총생산량 (GDP) 과의 상관관계는 불명확하거나 간접적인 것으로 알려져 있음 (Cointelegraph 2023; Cryptoslate 2022).\n\n역사적 사례\n\n2020년 COVID-19 위기 이후 BTC와 NDX의 상관관계가 강화됨 (Nasdaq 2020),\n2022년 5월 연방준비제도(Fed)의 금리 인상 발표 당시, BTC와 NDX 모두 하락.\n2023년 비트코인 빙하기 기간 동안 BTC와 NDX의 상관관계 변화 분석 필요.\n2024년 3월 비트코인 ETF가 출시하여 기관 투자자 참여가 증가와 함께께 BTC과 NDX의 coupling이 심해짐.\n\n\n주요 암호화폐 목록 및 카테고리\n\n\n\n\n\n\n\n\n암호화폐 (Cryptocurrency)\n심볼 (Ticker)\n카테고리 (Category)\n\n\n\n\n비트코인 (Bitcoin)\nBTC/USD\nLayer 1\n\n\n이더리움 (Ethereum)\nETH/USD\nLayer 1, Smart Contract\n\n\n테더 (Tether)\nUSDT/USD\nStablecoin\n\n\n리플 (XRP)\nXRP/USD\nPayment Network\n\n\n솔라나 (Solana)\nSOL/USD\nLayer 1\n\n\n체인링크 (Chainlink)\nLINK/USD\nOracle\n\n\n온도 (Ondo)\nONDO/USD\nReal-World Asset (RWA)\n\n\n카르다노 (Cardano)\nADA/USD\nLayer 1\n\n\n트론 (Tron)\nTRX/USD\nLayer 1\n\n\n도지코인 (Dogecoin)\nDOGE/USD\nMeme Coin\n\n\n\n\n\n암호화폐 관련 정보 제공 매체 리뷰\n\n시세 데이터 (Price Data): 실시간 및 과거 가격 변동, 거래량(volume) 등\n\nCoinMarketCap\nCoinGecko\n\n온체인 데이터 (On-Chain Data): 거래량, 지갑 주소 변화, 네트워크 활성도 등\n\nGlassnode\nIntoTheBlock\n\n시장 분석 (Market Analysis): 전문가 및 AI 기반 분석 리포트\n\nMessari\nCryptoQuant\n\n뉴스 및 이벤트 (News & Events): 프로젝트 업데이트, 규제 변화 등\n\nCoinDesk\nThe Block\n\n소셜 미디어 분석 (Social Media Analysis): 트위터(X), 레딧(Reddit) 등에서의 커뮤니티 반응\n\nLunarCrush\nSantiment"
  },
  {
    "objectID": "projects/correlation_crypto/correlation_crypto.html#데이터-분석",
    "href": "projects/correlation_crypto/correlation_crypto.html#데이터-분석",
    "title": "Correlation within Crypto-currencies",
    "section": "데이터 분석",
    "text": "데이터 분석\n\n데이터\n\n데이터 소스: FinanceDataReader\n데이터 기간: 2024년 3월 1일 - 2025년 2월 28일\n데이터 빈도 (Data Frequency): 일간(Daily)\n분석 대상 암호화폐:\n\nBTC/USD, ETH/USD, USDT/USD, XRP/USD, SOL/USD, LINK/USD, ONDO/USD, ADA/USD, TRX/USD, DOGE/USD\n\n롤링 윈도우 크기 (Rolling Window Size): 30일, 60일, 90일\n\n\n\n분석 방법\n\n암호화폐의 일간 수익률(daily return)을 계산.\n각 롤링 윈도우 크기(30, 60, 90일)에 대해 롤링 상관 행렬(rolling correlation matrix)을 계산.\n평균 상관계수(mean of rolling correlation matrix)를 도출하여 암호화폐 간의 관계를 분석.\n\n\n\nCode\n# 분석 결과 (Results)\n\n# 여러 거래소에서 지원하는 거래쌍을 확인\n\nimport ccxt\nimport pandas as pd\n\n# 주요 암호화폐 목록\nTICKER_COIN = ['BTC/USDT', 'ETH/USDT', 'USDT/USD', 'XRP/USDT', 'SOL/USDT', 'LINK/USDT', 'ONDO/USDT', 'ADA/USDT', 'TRX/USDT', 'DOGE/USDT']\n\n# 지원하는 거래소 목록\nexchanges = ['binance', 'kraken', 'bitfinex', 'poloniex']\n\n# 각 거래소에서 지원하는 거래쌍 확인\nfor exchange_id in exchanges:\n    exchange = getattr(ccxt, exchange_id)()\n    markets = exchange.load_markets()\n    supported_pairs = [pair for pair in TICKER_COIN if pair in markets]\n    print(f\"{exchange_id} supports: {supported_pairs}\")\n\n# 주요 암호화폐 목록\nbinance_tickers = ['BTC/USDT', 'ETH/USDT', 'XRP/USDT', 'SOL/USDT', 'LINK/USDT', 'ADA/USDT', 'TRX/USDT', 'DOGE/USDT']\nkraken_tickers = ['USDT/USD']\npoloniex_tickers = ['ONDO/USDT']\n\n# 데이터 기간 설정\nSTART_DATE = '2024-03-01'\nEND_DATE = '2025-02-28'\n\n# 거래소 설정\nbinance = ccxt.binance()\nkraken = ccxt.kraken()\npoloniex = ccxt.poloniex()\n\n# 데이터 불러오기 함수\ndef fetch_crypto_data(exchange, tickers, start, end):\n    data = {}\n    start_timestamp = exchange.parse8601(f'{start}T00:00:00Z')\n    end_timestamp = exchange.parse8601(f'{end}T00:00:00Z')\n    for ticker in tickers:\n        try:\n            ohlcv = exchange.fetch_ohlcv(ticker, '1d', since=start_timestamp, limit=1000)\n            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n            df.set_index('timestamp', inplace=True)\n            data[ticker] = df['close']\n        except Exception as e:\n            print(f\"Error fetching {ticker} from {exchange.id}: {e}\")\n    return pd.DataFrame(data)\n\n# 데이터 불러오기\nbinance_data = fetch_crypto_data(binance, binance_tickers, START_DATE, END_DATE)\nkraken_data = fetch_crypto_data(kraken, kraken_tickers, START_DATE, END_DATE)\npoloniex_data = fetch_crypto_data(poloniex, poloniex_tickers, START_DATE, END_DATE)\n\n# 모든 데이터를 하나의 DataFrame으로 병합\ncrypto_prices = pd.concat([binance_data, kraken_data, poloniex_data], axis=1)\n\n# 1) 일간 수익률 계산\ndef compute_returns(price_data: pd.DataFrame) -&gt; pd.DataFrame:\n    return price_data.pct_change().dropna(how='all')\n\ncrypto_returns = compute_returns(crypto_prices)\n\n# 2) 롤링 상관계수 계산\ndef rolling_correlation(returns: pd.DataFrame, window: int) -&gt; pd.DataFrame:\n    \"\"\"\n    returns: (date x tickers) DataFrame\n    window:  rolling window size (days)\n    \n    returns.rolling(window).corr() 결과는\n      - MultiIndex (date, ticker1)\n      - columns = ticker2\n    형태를 가집니다.\n    \"\"\"\n    corr_rolling = returns.rolling(window).corr()\n    return corr_rolling\n\n# 3) 날짜별 상관행렬을 모아서 평균 상관행렬을 산출\ndef average_correlation_matrix(returns: pd.DataFrame, window: int) -&gt; pd.DataFrame:\n    \"\"\"\n    - returns.rolling(window).corr() 결과를 사용\n    - 각 날짜별 (티커 x 티커) 상관행렬을 합산 후, 날짜 개수로 나누어 평균\n    \"\"\"\n    corr_rolling = rolling_correlation(returns, window)\n    \n    # MultiIndex에서 날짜(level=0) 목록을 추출\n    unique_dates = corr_rolling.index.get_level_values(0).unique()\n    tickers = returns.columns\n    \n    # 상관행렬 누적 합을 위한 (티커 x 티커) 형태의 빈 DataFrame\n    sum_matrix = pd.DataFrame(0.0, index=tickers, columns=tickers)\n    count = 0\n    \n    for date in unique_dates:\n        # (ticker1 x ticker2) 형태를 얻기 위해 xs(date, level=0)\n        date_corr = corr_rolling.xs(date, level=0)\n        # date_corr.index = ticker1, date_corr.columns = ticker2\n        \n        # 혹시 일부 티커에 대한 데이터가 누락되었을 경우를 대비하여 reindex\n        date_corr = date_corr.reindex(index=tickers, columns=tickers)\n        \n        # 날짜별 상관행렬(N x N)을 모두 누적\n        if date_corr.notna().all().all():\n            sum_matrix += date_corr.fillna(0.0)\n            count += 1\n    \n    # 평균 계산 (count가 0이 되지 않는다고 가정)\n    mean_matrix = sum_matrix / count\n    \n    return mean_matrix\n\n# 4) 롤링 상관계수 평균 계산\nrolling_corr_results = {}\nfor window in [30, 60, 90]:\n    mean_corr_matrix = average_correlation_matrix(crypto_returns, window)\n    rolling_corr_results[window] = mean_corr_matrix\n\n\nbinance supports: ['BTC/USDT', 'ETH/USDT', 'XRP/USDT', 'SOL/USDT', 'LINK/USDT', 'ADA/USDT', 'TRX/USDT', 'DOGE/USDT']\nkraken supports: ['BTC/USDT', 'ETH/USDT', 'USDT/USD', 'XRP/USDT', 'SOL/USDT', 'LINK/USDT', 'ADA/USDT', 'DOGE/USDT']\nbitfinex supports: ['BTC/USDT', 'ETH/USDT', 'USDT/USD', 'XRP/USDT', 'SOL/USDT', 'LINK/USDT', 'ADA/USDT', 'TRX/USDT', 'DOGE/USDT']\npoloniex supports: ['BTC/USDT', 'ETH/USDT', 'XRP/USDT', 'SOL/USDT', 'LINK/USDT', 'ONDO/USDT', 'ADA/USDT', 'TRX/USDT', 'DOGE/USDT']\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# 모든 행과 열이 출력되도록 설정\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.expand_frame_repr', False)\n\n# 결과 출력 및 시각화\nfor window, result in rolling_corr_results.items():\n    # 상관 행렬을 DataFrame으로 변환\n    result_df = result.dropna(how='all')\n    print(f\"\\n[Window = {window} days] Mean Correlation Matrix\\n\", result_df)\n    \n    # 히트맵 시각화\n    plt.figure(figsize=(10, 8))\n    \n    # 대각선 요소를 마스킹\n    mask = np.triu(np.ones(result_df.shape, dtype=bool))\n    \n    sns.heatmap(result_df, annot=True, cmap='coolwarm', center=0, mask=mask)\n    plt.title(f'Mean Rolling Correlation Matrix (Window Size: {window} days)')\n    plt.show()\n\n\n\n[Window = 30 days] Mean Correlation Matrix\n            BTC/USDT  ETH/USDT  XRP/USDT  SOL/USDT  LINK/USDT  ADA/USDT  TRX/USDT  DOGE/USDT  USDT/USD  ONDO/USDT\nBTC/USDT   1.000000  0.795572  0.560318  0.738323   0.678674  0.701705  0.378018   0.809802  0.445590   0.347956\nETH/USDT   0.795572  1.000000  0.549602  0.697997   0.732282  0.716344  0.373978   0.741247  0.277464   0.377371\nXRP/USDT   0.560318  0.549602  1.000000  0.542616   0.559794  0.644279  0.312014   0.582468  0.156470   0.222328\nSOL/USDT   0.738323  0.697997  0.542616  1.000000   0.667779  0.678928  0.312869   0.687971  0.243767   0.298119\nLINK/USDT  0.678674  0.732282  0.559794  0.667779   1.000000  0.757056  0.306468   0.661257  0.224121   0.411786\nADA/USDT   0.701705  0.716344  0.644279  0.678928   0.757056  1.000000  0.412296   0.722917  0.251557   0.329354\nTRX/USDT   0.378018  0.373978  0.312014  0.312869   0.306468  0.412296  1.000000   0.363110  0.173795   0.110995\nDOGE/USDT  0.809802  0.741247  0.582468  0.687971   0.661257  0.722917  0.363110   1.000000  0.307623   0.344026\nUSDT/USD   0.445590  0.277464  0.156470  0.243767   0.224121  0.251557  0.173795   0.307623  1.000000   0.238502\nONDO/USDT  0.347956  0.377371  0.222328  0.298119   0.411786  0.329354  0.110995   0.344026  0.238502   1.000000\n\n\n\n\n\n\n\n\n\n\n[Window = 60 days] Mean Correlation Matrix\n            BTC/USDT  ETH/USDT  XRP/USDT  SOL/USDT  LINK/USDT  ADA/USDT  TRX/USDT  DOGE/USDT  USDT/USD  ONDO/USDT\nBTC/USDT   1.000000  0.793590  0.506482  0.738719   0.658581  0.685800  0.310586   0.812013  0.437005   0.344612\nETH/USDT   0.793590  1.000000  0.488272  0.687174   0.704968  0.689430  0.297171   0.721429  0.284864   0.369260\nXRP/USDT   0.506482  0.488272  1.000000  0.493718   0.528005  0.622722  0.262692   0.529601  0.120305   0.199690\nSOL/USDT   0.738719  0.687174  0.493718  1.000000   0.648942  0.664811  0.266809   0.683149  0.234367   0.283011\nLINK/USDT  0.658581  0.704968  0.528005  0.648942   1.000000  0.743042  0.248022   0.631608  0.206315   0.396591\nADA/USDT   0.685800  0.689430  0.622722  0.664811   0.743042  1.000000  0.366473   0.707424  0.235716   0.313418\nTRX/USDT   0.310586  0.297171  0.262692  0.266809   0.248022  0.366473  1.000000   0.296148  0.145920   0.087218\nDOGE/USDT  0.812013  0.721429  0.529601  0.683149   0.631608  0.707424  0.296148   1.000000  0.304530   0.330517\nUSDT/USD   0.437005  0.284864  0.120305  0.234367   0.206315  0.235716  0.145920   0.304530  1.000000   0.239492\nONDO/USDT  0.344612  0.369260  0.199690  0.283011   0.396591  0.313418  0.087218   0.330517  0.239492   1.000000\n\n\n\n\n\n\n\n\n\n\n[Window = 90 days] Mean Correlation Matrix\n            BTC/USDT  ETH/USDT  XRP/USDT  SOL/USDT  LINK/USDT  ADA/USDT  TRX/USDT  DOGE/USDT  USDT/USD  ONDO/USDT\nBTC/USDT   1.000000  0.792191  0.463184  0.741261   0.641094  0.677995  0.259162   0.809258  0.422129   0.342049\nETH/USDT   0.792191  1.000000  0.439830  0.688451   0.691198  0.669859  0.228970   0.702804  0.276536   0.365459\nXRP/USDT   0.463184  0.439830  1.000000  0.445891   0.494987  0.601180  0.223155   0.484391  0.091303   0.187700\nSOL/USDT   0.741261  0.688451  0.445891  1.000000   0.632213  0.651429  0.242519   0.682041  0.234226   0.277772\nLINK/USDT  0.641094  0.691198  0.494987  0.632213   1.000000  0.727580  0.202533   0.603721  0.179637   0.383536\nADA/USDT   0.677995  0.669859  0.601180  0.651429   0.727580  1.000000  0.326810   0.692871  0.219931   0.301761\nTRX/USDT   0.259162  0.228970  0.223155  0.242519   0.202533  0.326810  1.000000   0.233808  0.116984   0.076352\nDOGE/USDT  0.809258  0.702804  0.484391  0.682041   0.603721  0.692871  0.233808   1.000000  0.291337   0.319852\nUSDT/USD   0.422129  0.276536  0.091303  0.234226   0.179637  0.219931  0.116984   0.291337  1.000000   0.243018\nONDO/USDT  0.342049  0.365459  0.187700  0.277772   0.383536  0.301761  0.076352   0.319852  0.243018   1.000000"
  },
  {
    "objectID": "projects/correlation_crypto/correlation_crypto.html#토론-discussions",
    "href": "projects/correlation_crypto/correlation_crypto.html#토론-discussions",
    "title": "Correlation within Crypto-currencies",
    "section": "토론 (Discussions)",
    "text": "토론 (Discussions)\n\n\n\n\n\n\nImportant\n\n\n\n변수들의 관찰 주기 (단기? 장기?)에 따라 또는 관찰 시기 (10년전? 지금?)에 따라 변수들 간의 선형관계는 유지되지 않을 수 있습니다. 2025년 현재 비트코인 (BTC) 가격은 시장 심리, 규제 변화, 기술적 요인 등에 크게 영향을 받고 있습니다.\n\n\n\n상관계수가 낮은 암호화폐 자산 조합을 식별하고, 헤지 투자 전략을 논의.\n특정 암호화폐 간의 높은 상관관계가 나타나는 이유 및 그에 따른 리스크 분석."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GitSAM",
    "section": "",
    "text": "내가 관심있는 것들…왜? 1."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "GitSAM",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n그냥요.↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "projects/corner_solution/corner_solution.html",
    "href": "projects/corner_solution/corner_solution.html",
    "title": "Corner Solutions in Optimization Model",
    "section": "",
    "text": "1. Introduction\nIn standard economic theory, both consumer preferences and production sets are generally assumed to exhibit convexity (Arrow and Debreu 1954; Debreu 1959). This assumption supports foundational results, including the existence and uniqueness of equilibrium and the efficiency of market allocations. In practice, however, features such as network externalities (Katz and Shapiro 1985; Rochet and Tirole 2003), rent-seeking (Shleifer and Vishny 1993), and multiple equilibria—often culminating in pronounced market dominance—can produce outcomes resembling non-convex preferences (Arthur 1994). In many cases, corner solutions and path-dependent equilibria emerge from winner-takes-all dynamics, concentrated economic power, and barriers to entry.\n\n\n2. Convexity in Economic Theory\n2.1 Convex Preferences and Production Sets\n\nConsumer preferences are typically modeled with quasi-concave utility functions, yielding convex (or “bowl-shaped”) indifference curves. This setup implies a preference for diversity in consumption, rather than extreme or corner solutions (Debreu 1959).\nProducers are often assumed to face diminishing marginal returns, reflected in a convex production possibility set. Under such conditions, output expansions follow a predictable pattern, and average costs rise eventually.\n\n2.2 Existence and Efficiency of Equilibrium\n\nWith convexity, free market entry, symmetric information, and price-taking behavior, perfectly competitive markets are shown to possess a stable equilibrium that is Pareto efficient (Arrow and Debreu 1954).\nThese results typically rely on fixed-point theorems and the properties of convex sets, ensuring both the existence of equilibrium prices and (in many cases) uniqueness or stability (Debreu 1959).\n\n2.3 Normative Implications\n\nConvexity underpins the normative stance that, absent significant market failures, competitive markets gravitate toward Pareto-efficient resource allocations.\nConsequently, government interventions usually aim to correct externalities, public goods issues, or information asymmetries within a broader context of largely convex preferences and production sets.\n\n\n\n3. Non-Convexities in Reality\n3.1 Network Externalities and Increasing Returns to Scale\n\nIn contrast to diminishing returns, many digital or platform-based markets exhibit network externalities, or increasing returns to scale (Katz and Shapiro 1985; Rochet and Tirole 2003). As additional users join a platform, its value to each user grows, often driving corner solutions in both production and consumption.\nInstead of smoothly concave utility or production functions, certain markets feature segments of increasing marginal returns, leading to “winner-takes-all” or “winner-take-most” dynamics.\n\n3.2 Coordination Games and Multiple Equilibria\n\nNetwork externalities commonly create coordination games, where each agent’s optimal choice depends on the choices of others. Small initial advantages or random shocks may tip the market toward a specific product or standard, resulting in lock-in (Arthur 1994).\nSuch scenarios can produce multiple Nash equilibria, for instance everyone choosing Product A or everyone choosing Product B, with potentially large welfare differences between them.\n\n3.3 Extreme or Corner Solutions in Consumption and Production\n\nWith robust network effects, consumers or producers may converge on a single brand, platform, or location, effectively marginalizing other options—even if those alternatives might have been preferred under purely convex preferences.\nThese corner solutions deviate from the classical idea that diversification in consumption and moderate scales in production yield optimal outcomes.\n\n3.4 Rent-Seeking and Incumbent Power\n\nDominant firms or groups can exploit political influence—through lobbying or regulatory capture—to fortify their positions, reinforcing non-convex outcomes by stifling competition (Tirole 1988; Shleifer and Vishny 1993).\nRent-seeking intensifies the misallocation of resources, as efforts are diverted to defending or reinforcing incumbents’ power, often via barriers to entry, reduced competition, and growing inequalities.\n\n\n\n4. Government Interventions\n4.1 Theoretical View: Correcting Market Imperfections\n\nTraditionally, policy interventions focus on addressing market failures, assuming that preferences and technologies remain fundamentally convex and that interventions are limited and transparent.\n\n4.2 Empirical Evidence: Policy Amplifies Non-Convexities\n\nIn reality, incumbents can wield outsized influence through lobbying and political capture, prompting policies that strengthen market concentration (Tirole 1988).\nInstead of fostering genuinely competitive markets, such policies may lock in non-convex outcomes, creating a vicious cycle of entrenched monopolistic power and limited competition.\n\n4.3 Lock-in and Path Dependence\n\nWhen policy-making aligns with incumbent interests, even minor advantages can become self-reinforcing (Arthur 1994).\nConsequently, once a market tips toward a specific firm, region, or product, effective competition may prove infeasible without sweeping policy reforms or disruptive innovation.\n\n\n\n5. Conclusion\nAlthough classical economic models lean on convex preferences and technologies to assert the existence of unique, efficient equilibria, real-world dynamics often revolve around non-convex phenomena. Network externalities, coordination failures, and rent-seeking can drive corner solutions, multiple equilibria, and lock-in that preserve incumbent advantages. Far from mitigating these issues, government policies sometimes exacerbate them through preferential treatment of dominant actors. Recognizing these non-convex realities is crucial for crafting policy frameworks that transcend purely theoretical assumptions of convexity and address the path-dependent complexity characterizing modern markets.\n\n\nAppendix: Utilitarian Objective function\n\n\nCode\n#@title Utilitarian objective function\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom scipy.optimize import minimize\n\n# 함수 정의\ndef z_function(x, y, a, b):\n  return y * (x**a) + (1 - y) * ((b - x)**a)\n\n# x, y 범위 및 매개변수 설정\na = 0.3  # 매개변수 a 값 (0과 1 사이)\nb = 20  # 매개변수 b 값\n\nx = np.linspace(0, b, 100)  # x 범위: 0부터 20까지 100개의 점\ny = np.linspace(0, 1, 100)  # y 범위: 0부터 1까지 100개의 점\nX, Y = np.meshgrid(x, y)  # x, y 좌표 격자 생성\n\n\n# Z 값 계산\nZ = z_function(X, Y, a, b)\n\n\ndef negative_z_function(params):\n    x, y = params\n    return -z_function(x, y, a, b)  # 최솟값을 찾기 위해 음수 값 반환\n\n# 초기값 설정 (interior 범위 내)\ninitial_guess = [b / 2, 0.5]\n\n# 경계 조건 설정\nbounds = [(0, b), (0, 1)]\n\n# 최적화 실행\nresult = minimize(negative_z_function, initial_guess, bounds=bounds)\n\n# 결과 추출\nextreme_point_x, extreme_point_y = result.x\nextreme_point_z = z_function(extreme_point_x, extreme_point_y, a, b)\n\nprint(\"Extreme Point (x, y, z):\", extreme_point_x, extreme_point_y, extreme_point_z)\n\n# Calculate Hessian matrix\ndef hessian_matrix(x, y, a, b):\n  \"\"\"Calculates the Hessian matrix of the z_function.\"\"\"\n  d2z_dx2 = a * (a - 1) * (y * (x**(a - 2)) + (1 - y) * ((b - x)**(a - 2)))\n  d2z_dy2 = 0  # Second derivative with respect to y is 0\n  d2z_dxdy = a * (x**(a - 1) - (b - x)**(a - 1))\n  d2z_dydx = d2z_dxdy  # Mixed partial derivatives are equal\n\n  return [[d2z_dx2, d2z_dxdy], [d2z_dydx, d2z_dy2]]\n\n# Determine the type of extreme point\nhessian = hessian_matrix(extreme_point_x, extreme_point_y, a, b)\ndeterminant = np.linalg.det(hessian)\n\nif determinant &gt; 0 and hessian[0][0] &gt; 0:\n  extreme_type = \"Minimum\"\nelif determinant &gt; 0 and hessian[0][0] &lt; 0:\n  extreme_type = \"Maximum\"\nelse:\n  extreme_type = \"Saddle\"\n\nprint(\"Extreme Point Type:\", extreme_type)\n\n\n# 3D 그래프 그리기\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.plot_surface(X, Y, Z)\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_zlabel('z')\nplt.title('3D Graph of z = y*x^a + (1-y)(b-x)^a')\n\n\n# global interior extreme point 표시\nax.scatter(extreme_point_x, extreme_point_y, extreme_point_z, color='red', marker='o', s=100)\nax.text(extreme_point_x, extreme_point_y, extreme_point_z, f'Extreme Point ({extreme_type})', color='red')\n\nplt.show()\n\n# Contour Plot 그리기\nfig, ax = plt.subplots()\ncontour = ax.contour(X, Y, Z)\nax.set_xlabel('x')\nax.set_ylabel('y')\nplt.title('Contour Plot of z = y*x^a + (1-y)(b-x)^a')\nplt.clabel(contour, inline=1, fontsize=10)\n\n# global interior extreme point 표시\nax.scatter(extreme_point_x, extreme_point_y, color='red', marker='o', s=100)\nax.text(extreme_point_x, extreme_point_y, 'Extreme Point', color='red')\n\nplt.show()\n\n\nExtreme Point (x, y, z): 10.0 0.5 1.9952623149688795\nExtreme Point Type: Saddle\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAppendix: Homogeneous function of degree 1\n\n\nCode\n# Define a return to scale\nscale = 1 # Constant return to scale, i.e. Homogeneous function of degree 1\n\n# Define parameter a\na = 1/4\n\n# total wealth of x\nk_x = 2\n# total wealth of y\nk_y = 2\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 경고 메시지 숨기기\nnp.seterr(invalid='ignore')\n\ndef numerical_derivative(f, X, Y, h=1e-5):\n    \"\"\" Compute numerical partial derivatives using central difference method.\"\"\"\n    dfdx = (f(X + h, Y) - f(X - h, Y)) / (2 * h)  # ∂f/∂x\n    dfdy = (f(X, Y + h) - f(X, Y - h)) / (2 * h)  # ∂f/∂y\n    return dfdx, dfdy\n\n# Define functions u_1(x,y) = x^a * y^(1-a) and u_2(x,y) = (2-x)(2-y)\ndef u1(x, y):\n    return x**(scale*a) * y**(scale*(1-a))\n\ndef u2(x, y):\n    return (k_x - x)**(scale*a) * (k_y - y)**(scale*(1-a))\n\n# Define the grid\nx = np.linspace(0, k_x, 15)\ny = np.linspace(0, k_y, 15)\nX, Y = np.meshgrid(x, y)\n\n# Compute the numerical derivatives (vector field components)\nU1, V1 = numerical_derivative(u1, X, Y)\nU2, V2 = numerical_derivative(u2, X, Y)\n\n# Reduce the density of vectors for better visualization\nx_sparse = np.linspace(0, k_x, 8)\ny_sparse = np.linspace(0, k_y, 8)\nX_sparse, Y_sparse = np.meshgrid(x_sparse, y_sparse)\nU1_sparse, V1_sparse = numerical_derivative(u1, X_sparse, Y_sparse)\nU2_sparse, V2_sparse = numerical_derivative(u2, X_sparse, Y_sparse)\n\n# Plot the combined vector fields and contour plots\n#plt.figure(figsize=(8, 8))\n\n# Contour plots of u_1 and u_2 (level curves only)\ncontour1 = plt.contour(X, Y, u1(X, Y), colors='blue', linestyles='solid', linewidths=1)\ncontour2 = plt.contour(X, Y, u2(X, Y), colors='red', linestyles='dashed', linewidths=1)\n\n# Overlay vector fields\nplt.quiver(X_sparse, Y_sparse, U1_sparse, V1_sparse, color='b', angles='xy', label='∇$u_1$')\nplt.quiver(X_sparse, Y_sparse, U2_sparse, V2_sparse, color='r', angles='xy', label='∇$u_2$')\n\n# Labels and grid\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Gradient Vector Fields & Level Curves of $u_1$ and $u_2$')\nplt.legend()\nplt.grid('scaled')\nplt.axis('square')\n\nplt.tight_layout()\n# Show the plot\nplt.show()\n\n# Compute the sum of gradients\nU_sum = U1 + U2\nV_sum = V1 + V2\n\n# Reduce the density of vectors for better visualization\nU_sum_sparse, V_sum_sparse = numerical_derivative(lambda x, y: u1(x, y) + u2(x, y), X_sparse, Y_sparse)\n\n# Plot the combined vector fields and contour plots\n#plt.figure(figsize=(8, 8))\n\n# Contour plots of u_1 and u_2 (level curves only)\ncontour1 = plt.contour(X, Y, u1(X, Y), colors='blue', linestyles='solid', linewidths=1)\ncontour2 = plt.contour(X, Y, u2(X, Y), colors='red', linestyles='dashed', linewidths=1)\n\n# Overlay sum of gradient vector fields\nplt.quiver(X_sparse, Y_sparse, U_sum_sparse, V_sum_sparse, color='g', angles='xy', label='∇($u_1 + u_2$)')\n\n# Labels and grid\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sum of Gradient Vector Fields & Level Curves of $u_1$ and $u_2$')\nplt.legend()\n\nplt.grid('scaled')\nplt.axis('square')\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAppendix: Sigmoid utility function\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Define constants\nkx = (np.pi**3 / 2) ** (1/3)\nky = (2**(1/2)) * ((np.pi**3 / 2) ** (1/3))\n\n# Define the grid\nx = np.linspace(0, kx, 1000)\ny = np.linspace(0, ky, 1000)\nX, Y = np.meshgrid(x, y)\n\n# Define the functions\nu1 = 1 - np.cos(X**(1/3) * Y**(2/3))\nu2 = 1 - np.cos((kx - X)**(1/3) * (ky - Y)**(2/3))\n\n# Find intersection points where u1 == u2\nthreshold = 1e-3  # Numerical tolerance for equality\nintersection_mask = np.abs(u1 - u2) &lt; threshold\nX_intersect = X[intersection_mask]\nY_intersect = Y[intersection_mask]\nZ_intersect = u1[intersection_mask]  # u1 and u2 are nearly equal\n\n# Create 3D plot\nfig = plt.figure(figsize=(8, 6))\nax = fig.add_subplot(111, projection='3d')\n\n# Plot intersection line\nax.scatter(X_intersect, Y_intersect, Z_intersect, color='black', s=10, label='Intersection Line')\n\n# Surface plots for reference\nax.plot_surface(X, Y, u1, cmap='Blues', alpha=0.5)\nax.plot_surface(X, Y, u2, cmap='Reds', alpha=0.5)\n\n# Labels and title\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_zlabel('Z')\nax.set_title('3D Intersection of $u_1$ and $u_2$')\nax.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nArrow, Kenneth J., and Gerard Debreu. 1954. “Existence of an Equilibrium for a Competitive Economy.” Econometrica 22 (3): 265–90.\n\n\nArthur, W. Brian. 1994. Increasing Returns and Path Dependence in the Economy. Ann Arbor, MI: University of Michigan Press.\n\n\nDebreu, Gerard. 1959. Theory of Value: An Axiomatic Analysis of Economic Equilibrium. New Haven, CT: Yale University Press.\n\n\nKatz, Michael L., and Carl Shapiro. 1985. “Network Externalities, Competition, and Compatibility.” The American Economic Review 75 (3): 424–40.\n\n\nRochet, Jean-Charles, and Jean Tirole. 2003. “Platform Competition in Two-Sided Markets.” Journal of the European Economic Association 1 (4): 990–1029.\n\n\nShleifer, Andrei, and Robert W. Vishny. 1993. “Corruption.” The Quarterly Journal of Economics 108 (3): 599–617.\n\n\nTirole, Jean. 1988. The Theory of Industrial Organization. Cambridge, MA: MIT Press."
  },
  {
    "objectID": "projects/dichotomy/dichotomy.html",
    "href": "projects/dichotomy/dichotomy.html",
    "title": "Identifying the Most Significant Dichotomy",
    "section": "",
    "text": "Wealth concentration and inequality have long been central issues in economics, attracting renewed attention as wealth disparities continue to widen. The well-documented Pareto Principle suggests that the top 20% holds approximately 80% of total wealth, but empirical studies indicate that this ratio has become even more skewed over time (Piketty and Saez 2003; Alvaredo et al. 2013; Saez and Zucman 2016). Such trends raise fundamental questions about the underlying dynamics of wealth distribution: Is wealth accumulation a zero-sum game? If so, what is the most evident dichotomy that best exposes this phenomenon?\nAt every moment, newly created capital is introduced into the economic system through production, subsequently distributed among economic agents, and then either dissipated through consumption or retained through investment. Unlike a static framework where total wealth is fixed, real-world economic systems operate as dynamic entities where total wealth evolves over time. The interplay between production, distribution, consumption, and investment determines how wealth is allocated and reallocated across different socioeconomic groups. If the system maintains a stable and proportional allocation of new wealth over time, the relative shares of net worth for different groups remain unchanged. However, if allocation mechanisms fluctuate, then the wealth share of one group necessarily increases at the expense of another—reinforcing a zero-sum dynamic.\nThe key question, therefore, is: How should we partition the population to most clearly expose this zero-sum characteristic? In other words, at which wealth cutoff percentile do we observe the highest absolute correlation between two complementary wealth groups? Should we divide the population into the top 10% versus the bottom 90%? Or is a more extreme division, such as top 0.1% versus bottom 99.9%, more effective in revealing these dynamics?"
  },
  {
    "objectID": "projects/dichotomy/dichotomy.html#introduction",
    "href": "projects/dichotomy/dichotomy.html#introduction",
    "title": "Identifying the Most Significant Dichotomy",
    "section": "",
    "text": "Wealth concentration and inequality have long been central issues in economics, attracting renewed attention as wealth disparities continue to widen. The well-documented Pareto Principle suggests that the top 20% holds approximately 80% of total wealth, but empirical studies indicate that this ratio has become even more skewed over time (Piketty and Saez 2003; Alvaredo et al. 2013; Saez and Zucman 2016). Such trends raise fundamental questions about the underlying dynamics of wealth distribution: Is wealth accumulation a zero-sum game? If so, what is the most evident dichotomy that best exposes this phenomenon?\nAt every moment, newly created capital is introduced into the economic system through production, subsequently distributed among economic agents, and then either dissipated through consumption or retained through investment. Unlike a static framework where total wealth is fixed, real-world economic systems operate as dynamic entities where total wealth evolves over time. The interplay between production, distribution, consumption, and investment determines how wealth is allocated and reallocated across different socioeconomic groups. If the system maintains a stable and proportional allocation of new wealth over time, the relative shares of net worth for different groups remain unchanged. However, if allocation mechanisms fluctuate, then the wealth share of one group necessarily increases at the expense of another—reinforcing a zero-sum dynamic.\nThe key question, therefore, is: How should we partition the population to most clearly expose this zero-sum characteristic? In other words, at which wealth cutoff percentile do we observe the highest absolute correlation between two complementary wealth groups? Should we divide the population into the top 10% versus the bottom 90%? Or is a more extreme division, such as top 0.1% versus bottom 99.9%, more effective in revealing these dynamics?"
  },
  {
    "objectID": "projects/dichotomy/dichotomy.html#data",
    "href": "projects/dichotomy/dichotomy.html#data",
    "title": "Identifying the Most Significant Dichotomy",
    "section": "Data",
    "text": "Data\nOur empirical analysis is based on FRED (Federal Reserve Economic Data), covering quarterly observations from 1989 to 2024. The dataset is structured into wealth brackets representing net wealth shares at different percentile levels:\nGroups (stars)\n\n\\(X_4(t)\\): Share of Net Worth Held by the Top 0.1% (99.9th to 100th Wealth Percentiles) (WFRBSTP1300)\n\\(X_3(t)\\): Share of Net Worth Held by the 99th to 99.9th Wealth Percentiles (WFRBS99T999273)\n\nc.f. Share of Net Worth Held by the Top 1% (99th to 100th Wealth Percentiles) (WFRBST01134)\n\n\\(X_2(t)\\): Share of Net Worth Held by the 90th to 99th Wealth Percentiles (WFRBSN09161)\n\\(X_1(t)\\): Share of Net Worth Held by the 50th to 90th Wealth Percentiles (WFRBSN40188)\n\\(X_0(t)\\): Share of Net Worth Held by the Bottom 50% (1st to 50th Wealth Percentiles) (WFRBSB50215)\n\nAdditionally, we reference wealth cutoff amount to identify the minimum level of wealth required to belong to specific top percentile groups:\nCutoff Levels (bins)\n\n\\(p_4\\) or 99.9th: Minimum Wealth Cutoff for the Top 0.1% (99.9th to 100th Wealth Percentiles) (WFRBLTP1311)\n\\(p_3\\) or 99th: Minimum Wealth Cutoff for the 99th to 99.9th Wealth Percentiles (WFRBL99T999309)\n\\(p_2\\) or 90th: Minimum Wealth Cutoff for the 90th to 99th Wealth Percentiles (WFRBLN09304)\n\\(p_1\\) or 50th: Minimum Wealth Cutoff for the 50th to 90th Wealth Percentiles (WFRBLN40302)"
  },
  {
    "objectID": "projects/dichotomy/dichotomy.html#methodology",
    "href": "projects/dichotomy/dichotomy.html#methodology",
    "title": "Identifying the Most Significant Dichotomy",
    "section": "Methodology",
    "text": "Methodology\nGiven that total share of net wealth must always sum to one, any partition of the population into two groups remains complementary: \\[\nX_0 + X_1 + X_2 + X_3 + X_4 = 1.\n\\]\nTo quantify the most evident dichotomy, we define two complementary wealth groups for different percentile cutoffs:\n\nWhen \\(p = p_1\\):\n\\[\n  a(t) = X_4(t)+X_3(t)+X_2(t)+X_1(t), \\quad b(t) = X_0(t).\n\\]\nWhen \\(p = p_2\\):\n\\[\n  a(t) = X_4(t)+X_3(t)+X_2(t), \\quad b(t) = X_1(t)+X_0(t).\n\\]\nWhen \\(p = p_3\\):\n\\[\n  a(t) = X_4(t)+X_3(t), \\quad b(t) = X_2(t)+X_1(t)+X_0(t).\n\\]\nWhen \\(p = p_4\\):\n\\[\n  a(t) = X_4(t), \\quad b(t) = X_3(t)+X_2(t)+X_1(t)+X_0(t).\n\\]\n\nFor each cutoff \\(p\\), we compute the correlation:\n\\[\n   y(p) = \\mathrm{corr}\\bigl(a(t),\\,b(t)\\bigr).\n\\]\nWe seek the wealth cutoff \\(p\\) that maximizes the absolute correlation \\(|y(p)|\\), revealing the strongest inverse relationship between the two resulting wealth groups. A high absolute correlation suggests that fluctuations in one group’s net worth share are systematically mirrored by the other, reinforcing the zero-sum nature of wealth accumulation. This dichotomy provides insight into how different capital accumulation mechanisms—through labor or capital investment—shape long-term wealth distribution.\nStrong inverse correlations at certain percentiles may indicate critical thresholds where redistribution policies—such as capital taxation or inheritance taxation—could have the most pronounced effects (Piketty 2011; Piketty, Saez, and Stantcheva 2014; Saez and Zucman 2016)."
  },
  {
    "objectID": "projects/dichotomy/dichotomy.html#empirical-results",
    "href": "projects/dichotomy/dichotomy.html#empirical-results",
    "title": "Identifying the Most Significant Dichotomy",
    "section": "Empirical Results",
    "text": "Empirical Results\nAfter processing the quarterly dataset (excluding missing values), we find that the 90th percentile cutoff (\\(p_2\\)) exhibits the highest absolute correlation between the two complementary wealth groups. Specifically, as of 2022-07-01, the minimum wealth required to be in the top 10% was approximately $2,152,788.\nThis suggests that dividing the population into top 10% vs. bottom 90% most effectively reveals the zero-sum nature of wealth redistribution, compared to other partitions such as top 50% vs. bottom 50% or top 0.1% vs. bottom 99.9%.\nThese findings imply that the most structurally significant wealth division occurs between the top 10% and the rest, rather than between the ultra-rich and lower percentiles. This observation aligns with broader discussions on wealth polarization, where the top 10% increasingly dominates capital ownership while the bottom 90% exhibits a more recessive trajectory."
  },
  {
    "objectID": "projects/dichotomy/dichotomy.html#conclusions",
    "href": "projects/dichotomy/dichotomy.html#conclusions",
    "title": "Identifying the Most Significant Dichotomy",
    "section": "Conclusions",
    "text": "Conclusions\nThis study demonstrates that partitioning the population at the 90th wealth percentile provides the most evident dichotomy in revealing the zero-sum nature of capital accumulation. Over time, wealth redistribution mechanisms result in strong inverse correlations between net worth shares of different groups, underscoring the struggling aspects of capital accumulation. The analysis suggests that the structural division between the top 10% and the bottom 90% is more significant than commonly assumed top 1% vs. bottom 99% splits, reinforcing the notion that wealth concentration extends beyond the ultra-rich and affects broader socioeconomic strata.\nThese findings hold important implications for public policy, particularly in debates surrounding progressive taxation, capital gains policies, and inheritance tax structures. A strong inverse correlation at the 90th percentile threshold suggests that redistributive policies targeted at this level could have significant implications for long-term wealth dynamics. This aligns with prior research emphasizing the role of tax policy in shaping wealth accumulation patterns and mitigating excessive concentration of economic power (Piketty, Saez, and Stantcheva 2014; Saez and Zucman 2016).\nWhile this study primarily focuses on empirical correlation analysis, future research should explore additional macroeconomic variables to refine our understanding of wealth distribution dynamics. Incorporating GDP growth rates, investment patterns, labor market structures, and monetary policy changes may provide further insights into how systemic wealth flows evolve in response to economic shocks and policy interventions. Additionally, extending the dataset to include international comparisons could offer a broader perspective on whether the 90th percentile threshold serves as a critical inflection point for wealth inequality across different economies. Further research integrating both empirical and theoretical approaches will be essential in developing more effective strategies for addressing wealth concentration and economic mobility.\n\n\nCode\nimport pandas as pd\nimport pandas_datareader.data as web\nimport matplotlib.pyplot as plt\n\n# 데이터 기간 설정\nstart_date = '1989-07-01'\nend_date = '2024-07-01'\n\n# FRED 데이터 가져오기\nseries_ids = {\n    'X_4': 'WFRBSTP1300',\n    'X_3': 'WFRBS99T999273',\n    'X_2': 'WFRBSN09161',\n    'X_1': 'WFRBSN40188',\n    'X_0': 'WFRBSB50215'\n}\n\ndata = pd.DataFrame()\nfor name, series_id in series_ids.items():\n    data[name] = web.DataReader(series_id, 'fred', start_date, end_date)\n\n# 결측값 제거\ndata.dropna(inplace=True)\n\n\n# FRED에서 wealth level 데이터 가져오기\nwealth_level_ids = {\n    1: 'WFRBLN40302',\n    2: 'WFRBLN09304',\n    3: 'WFRBL99T999309',\n    4: 'WFRBLTP1311'\n}\n\nwealth_levels = {}\nfor p, series_id in wealth_level_ids.items():\n    latest_data = web.DataReader(series_id, 'fred', start_date, end_date).dropna().iloc[-1]\n    wealth_levels[p] = (latest_data.name, latest_data.iloc[0])  # 날짜와 값을 함께 저장\n    \n# 총 관측치 수 출력\nprint(f\"Total number of observations after removing NaN values: {len(data)}\")\n\n\nTotal number of observations after removing NaN values: 141\n\n\n\n\nCode\n# 상관관계 계산 함수\ndef calculate_correlation(a, b):\n    return a.corr(b)\n\n# 상관관계 계산\ncorrelations = {\n    1: calculate_correlation(data['X_4'] + data['X_3'] + data['X_2'] + data['X_1'], data['X_0']),\n    2: calculate_correlation(data['X_4'] + data['X_3'] + data['X_2'], data['X_1'] + data['X_0']),\n    3: calculate_correlation(data['X_4'] + data['X_3'], data['X_2'] + data['X_1'] + data['X_0']),\n    4: calculate_correlation(data['X_4'], data['X_3'] + data['X_2'] + data['X_1'] + data['X_0'])\n}\n\n# 결과 출력\nfor p, y in correlations.items():\n    print(f\"Correlation for p_{p}: {y:.4f}\")\n\n# 최소 상관관계를 가지는 wealth percentile 찾기\nmin_corr_p = min(correlations, key=correlations.get)\npercentile_map = {1: \"50th\", 2: \"90th\", 3: \"99th\", 4: \"99.9th\"}\nprint(f\"Minimum correlation is at p_{min_corr_p}: {percentile_map[min_corr_p]}\")\nwealth_date, wealth_level = wealth_levels[min_corr_p]\nprint(f\"Wealth level for {percentile_map[min_corr_p]} percentile on {wealth_date.date()}: ${wealth_level:,.0f}\")\n\n\n# 그래프 표현\np_values = list(correlations.keys())\ny_values = list(correlations.values())\n\nplt.plot(p_values, y_values, marker='o')\nplt.xlabel('Wealth Cutoff (p)')\nplt.ylabel('Correlation (y(p))')\nplt.title('Wealth Cutoff vs Correlation')\nplt.grid(True)\nplt.show()\n\n\nCorrelation for p_1: -0.9980\nCorrelation for p_2: -0.9998\nCorrelation for p_3: -0.9996\nCorrelation for p_4: -0.9987\nMinimum correlation is at p_2: 90th\nWealth level for 90th percentile on 2022-07-01: $2,152,788"
  },
  {
    "objectID": "projects/pareto_index/pareto_index.html",
    "href": "projects/pareto_index/pareto_index.html",
    "title": "Approximating Wealth Distribution",
    "section": "",
    "text": "The Pareto distribution has long been used to model wealth or income distributions, starting from the seminal work of Vilfredo Pareto in the late 19th century (Pareto 1964). One of the most intuitive ways to visualize the inequality within such a distribution is through the Lorenz curve, introduced by Lorenz in 1905 (Lorenz 1905). The Lorenz curve describes the cumulative proportion of total wealth (or resources) held by the bottom fraction of the population. Closely related to the Lorenz curve is the Gini coefficient, which provides a scalar measure of inequality (Gini 1912).\nThis document first derives the Lorenz curve for a Pareto distribution, then demonstrates how to estimate the Pareto index (shape parameter) from Lorenz curve observations. We additionally relate the Pareto distribution to Constant Relative Risk Aversion (CRRA) utility function, highlighting the same shared structure in a differential equation that governs both."
  },
  {
    "objectID": "projects/pareto_index/pareto_index.html#introduction",
    "href": "projects/pareto_index/pareto_index.html#introduction",
    "title": "Approximating Wealth Distribution",
    "section": "",
    "text": "The Pareto distribution has long been used to model wealth or income distributions, starting from the seminal work of Vilfredo Pareto in the late 19th century (Pareto 1964). One of the most intuitive ways to visualize the inequality within such a distribution is through the Lorenz curve, introduced by Lorenz in 1905 (Lorenz 1905). The Lorenz curve describes the cumulative proportion of total wealth (or resources) held by the bottom fraction of the population. Closely related to the Lorenz curve is the Gini coefficient, which provides a scalar measure of inequality (Gini 1912).\nThis document first derives the Lorenz curve for a Pareto distribution, then demonstrates how to estimate the Pareto index (shape parameter) from Lorenz curve observations. We additionally relate the Pareto distribution to Constant Relative Risk Aversion (CRRA) utility function, highlighting the same shared structure in a differential equation that governs both."
  },
  {
    "objectID": "projects/pareto_index/pareto_index.html#deriving-the-lorenz-curve-of-a-pareto-distribution",
    "href": "projects/pareto_index/pareto_index.html#deriving-the-lorenz-curve-of-a-pareto-distribution",
    "title": "Approximating Wealth Distribution",
    "section": "2. Deriving the Lorenz Curve of a Pareto Distribution",
    "text": "2. Deriving the Lorenz Curve of a Pareto Distribution\n\n2.1. Definition of the Lorenz Curve\nFor a continuous distribution of wealth (X), the Lorenz curve \\(L(p)\\) is defined as the fraction of total wealth owned by the bottom \\(p\\) fraction of the population:\n\\[\nL(p) \\;=\\; \\frac{\\int_{x_m}^{x(p)} x\\,f(x)\\,dx}{\\int_{x_m}^{\\infty} x\\,f(x)\\,dx},\n\\]\nwhere\n\n\\(p = F\\bigl(x(p)\\bigr)\\) is the cumulative proportion of individuals with wealth below \\(x(p)\\),\nThe numerator represents the cumulative wealth of the bottom \\(p\\) fraction,\nThe denominator represents the total wealth in the system, given by the expected value of \\(X\\) over its support.\n\n\n\n2.2. Pareto Distribution\nA Pareto distribution with shape parameter \\(\\alpha&gt;0\\) and scale parameter \\(x_m&gt;0\\) is defined by the PDF\n\\[\nf(x) \\;=\\; \\alpha\\,\\frac{x_m^\\alpha}{x^{\\alpha+1}},\n\\quad x \\ge x_m,\n\\]\nand the corresponding CDF\n\\[\nF(x) \\;=\\; 1 \\;-\\;\\Bigl(\\tfrac{x_m}{x}\\Bigr)^\\alpha,\n\\quad x \\ge x_m.\n\\]\nEquivalently, for \\(0 &lt; p &lt; 1\\), the quantile \\(x(p)\\) satisfying \\(F\\bigl(x(p)\\bigr)=p\\) is\n\\[\np \\;=\\; 1 \\;-\\;\\Bigl(\\tfrac{x_m}{x(p)}\\Bigr)^\\alpha\n\\;\\;\\Longleftrightarrow\\;\\;\nx(p) \\;=\\; \\frac{x_m}{\\bigl(1 - p\\bigr)^{1/\\alpha}}.\n\\]\n\n\n2.3. Total Wealth\nLet the total wealth be \\(W_{\\text{total}} = E[X]\\), the expected value of \\(X\\). Substituting the PDF of the Pareto distribution into the definition of expectation,\n\\[\nE[X]\n\\;=\\; \\int_{x_m}^{\\infty} x\\,f(x)\\,dx\n\\;=\\; \\int_{x_m}^{\\infty} x \\,\\alpha\\,\\frac{x_m^\\alpha}{x^{\\alpha+1}}\\,dx\n\\;=\\; \\alpha\\,x_m^\\alpha \\int_{x_m}^{\\infty} x^{-\\alpha}\\,dx.\n\\]\nFor \\(\\alpha&gt;1\\), the improper integral converges and we obtain\n\\[\nW_{\\text{total}}\n\\;=\\; E[X]\n\\;=\\; \\frac{\\alpha\\,x_m}{\\alpha - 1}.\n\\]\n\n\n2.4. Cumulative Wealth for the Bottom \\(p\\) Fraction\nThe cumulative wealth held by the bottom \\(p\\) fraction is\n\\[\nW(p)\n\\;=\\;\\int_{x_m}^{x(p)} x\\,f(x)\\,dx\n\\;=\\;\\alpha\\,x_m^\\alpha \\int_{x_m}^{x(p)} x^{-\\alpha}\\,dx\n\\;=\\;\\alpha\\,x_m^\\alpha\n\\Bigl[\\frac{x^{-\\alpha+1}}{-\\alpha+1}\\Bigr]_{x_m}^{x(p)}.\n\\]\nSimplifying,\n\\[\nW(p)\n\\;=\\; \\frac{\\alpha\\,x_m}{\\alpha - 1}\n\\;\\Bigl(1 - \\bigl(\\tfrac{x_m}{x(p)}\\bigr)^{\\alpha - 1}\\Bigr).\n\\]\n\n\n2.5. Lorenz Curve for the Pareto Distribution\nBy definition,\n\\[\nL(p)\n\\;=\\; \\frac{W(p)}{W_{\\text{total}}}\n\\;=\\; \\frac{\\frac{\\alpha\\,x_m}{\\alpha - 1}\\,\\Bigl(1 - \\bigl(\\tfrac{x_m}{x(p)}\\bigr)^{\\alpha - 1}\\Bigr)}\n            {\\frac{\\alpha\\,x_m}{\\alpha - 1}}\n\\;=\\; 1 - \\bigl(1 - p\\bigr)^{\\frac{\\alpha - 1}{\\alpha}}.\n\\]\nHence, for a Pareto distribution, the Lorenz curve is\n\\[\nL(p) \\;=\\; 1 \\;-\\; \\bigl(1 - p\\bigr)^{\\tfrac{\\alpha - 1}{\\alpha}}.\n\\]\n\nIf \\(\\alpha \\gg 1\\), the distribution is more equal, and \\(L(p)\\) is closer to the 45-degree line of perfect equality.\n\nIf \\(\\alpha\\) is only slightly larger than 1, the distribution is more unequal, with significant concentration of wealth in the upper tail."
  },
  {
    "objectID": "projects/pareto_index/pareto_index.html#estimating-the-pareto-index-from-the-lorenz-curve",
    "href": "projects/pareto_index/pareto_index.html#estimating-the-pareto-index-from-the-lorenz-curve",
    "title": "Approximating Wealth Distribution",
    "section": "3. Estimating the Pareto Index from the Lorenz Curve",
    "text": "3. Estimating the Pareto Index from the Lorenz Curve\nSuppose empirical data or external studies indicate specific points \\((p, L(p))\\) on the Lorenz curve. We can use\n\\[\nL(p) \\;=\\; 1 - (1 - p)^{\\frac{\\alpha - 1}{\\alpha}}\n\\]\nto solve numerically for \\(\\alpha\\). Commonly cited examples:\nSeveral Empirical Illustrations\n\nPareto 80:20 Rule: \\(p=0.80\\), \\(L(p)=0.20\\)\n\\(\\Rightarrow\\) \\(\\alpha \\approx \\frac{\\ln(4)}{\\ln(5)} \\approx 1.16\\).\nPareto 90:10 Rule: \\(p=0.90\\), \\(L(p)=0.10\\)\n\\(\\Rightarrow\\) \\(\\alpha \\approx 1.05\\).\nU.S. Stock Market: According to a report by Axios (2024), the top 10% own about 93% of total equity wealth, implying \\(p=0.90\\) and \\(L(p)=0.07\\). Solving yields \\(\\alpha \\approx 1.03\\).\n\nCredit Suisse Global Wealth Report: In 2013, it was reported that the top 1% control about 50% of global wealth, which implies \\(p=0.99\\) and \\(L(p)=0.50\\). Solving gives \\(\\alpha \\approx 1.18\\). Additionally, the top 10% were said to own about 85% of global wealth (\\(p=0.90\\), \\(L(p)=0.15\\)), giving \\(\\alpha \\approx 1.08\\). Comparing such estimates across years (e.g., 2013 vs. 2020) can reveal the time dynamics of the global wealth distribution (Credit Suisse 2013, 2020)."
  },
  {
    "objectID": "projects/pareto_index/pareto_index.html#the-gini-coefficient",
    "href": "projects/pareto_index/pareto_index.html#the-gini-coefficient",
    "title": "Approximating Wealth Distribution",
    "section": "4. The Gini Coefficient",
    "text": "4. The Gini Coefficient\nThe Gini coefficient is a measure of wealth or income inequality that is closely related to the Lorenz curve. The Gini coefficient is defined as the ratio of the area between the Lorenz curve and the 45-degree equality line to the total area under the 45-degree line. Mathematically, the Gini coefficient ( G ) is given by:\n\\[\nG = 1 - 2 \\int_0^1 L(p) \\, dp.\n\\]\nSubstituting the Lorenz curve for a Pareto distribution:\n\\[\nL(p) = 1 - (1 - p)^{\\frac{\\alpha - 1}{\\alpha}},\n\\]\nwe obtain:\n\\[\nG = 1 - 2 \\int_0^1 \\big[1 - (1 - p)^{\\frac{\\alpha - 1}{\\alpha}}\\big] \\, dp = \\frac{1}{2\\alpha - 1}.\n\\]\nThus, for a Pareto distribution, the Gini coefficient is:\n\\[\nG = \\frac{1}{2\\alpha - 1}, \\quad \\text{for } \\alpha &gt; \\frac{1}{2}.\n\\]\nSome features of the Gini coefficient:\n\nAs \\(\\alpha \\to 1^+\\), the Gini coefficient approaches 1, indicating extreme inequality (a few individuals hold nearly all the wealth).\nAs \\(\\alpha \\to \\infty\\), the Gini coefficient approaches 0, indicating perfect equality.\nFor typical empirical values of \\(\\alpha\\) in wealth distributions (e.g., 1.1 to 1.8), the Gini coefficient ranges from 0.83 to 0.38, reflecting significant inequality\nRelative measure: \\(G\\) compares the distribution to perfect equality, but does not capture absolute differences.\n\nNon‐additivity: One cannot simply average the Gini coefficients of subpopulations to obtain an overall Gini coefficient.\n\nSensitivity: The Gini coefficient is sensitive to changes in the middle of the distribution, but less so at the tails."
  },
  {
    "objectID": "projects/pareto_index/pareto_index.html#pareto-distribution-and-crra-utility",
    "href": "projects/pareto_index/pareto_index.html#pareto-distribution-and-crra-utility",
    "title": "Approximating Wealth Distribution",
    "section": "5. Pareto Distribution and CRRA Utility",
    "text": "5. Pareto Distribution and CRRA Utility\nIn microeconomic theory, a widely used utility specification is the Constant Relative Risk Aversion (CRRA) form (Arrow et al. 1974; Pratt 1978). The CRRA utility function \\(u(x)\\) satisfies\n\\[\n-\\frac{x\\,u''(x)}{u'(x)} \\;=\\; \\gamma,\n\\]\nwhere \\(\\gamma&gt;0\\) is the coefficient of relative risk aversion. Solving for \\(u(x)\\) under boundary conditions such as \\(u(1)=0\\) yields:\n\nIf \\(\\gamma=1\\), \\(u(x)=\\ln x\\). (using the L’hopital’s Rule)\nIf \\(\\gamma\\neq 1\\), \\(u(x)=\\frac{x^{\\,1-\\gamma}-1}{\\,1-\\gamma\\,}\\).\n\nLarger \\(\\gamma\\) indicates higher risk aversion, while \\(\\gamma=0\\) corresponds to risk neutrality (\\(u(x)=x\\)).\nA Pareto PDF can also be derived from a differential equation with similar form. If \\(f(x)\\) is the PDF of a Pareto random variable on \\(x\\ge x_m&gt;0\\), one can write:\n\\[\n-\\frac{x\\,f'(x)}{\\,f(x)\\!}\\;=\\;(1+\\alpha)\\,x_m^{\\alpha},\n\\]\nwhich likewise has a “power‐law” solution structure. Thus, Pareto distributions and CRRA utilities each emerge from a linear differential equation of analogous form, underscoring a conceptual parallel in how “power‐type” functional solutions can appear in both economic choice models (through marginal utility) and in heavy‐tailed probability distributions.\nFurthermore, in mainstream economic theory, marginal utility \\(u'(x)\\) is assumed to be strictly positive, and \\(u''(x)\\) typically negative (diminishing marginal utility). In probability theory, any valid PDF \\(f(x)\\) must be positive, and for heavy‐tailed distributions like Pareto, \\(f(x)\\) decreases for large \\(x\\). These parallels lead to a one‐to‐one analogy between certain types of declining utilities and distributions whose density functions also decline in \\(x\\).\n\nRemark: There is a well‐known relationship via logarithmic transforms: if \\(X\\) is Pareto(\\(x_m,\\alpha\\)), then \\(Y=\\ln(X/x_m)\\) is exponentially distributed with rate \\(\\alpha\\). This exponential distribution also arises from a first‐order linear differential equation, reinforcing these structural similarities."
  },
  {
    "objectID": "projects/pareto_index/pareto_index.html#conclusion",
    "href": "projects/pareto_index/pareto_index.html#conclusion",
    "title": "Approximating Wealth Distribution",
    "section": "6. Conclusion",
    "text": "6. Conclusion\nBecause the Pareto distribution has only two parameters (\\(x_m\\) and \\(\\alpha\\)), even minimal distributional data—such as “the bottom 80% own 20% of total wealth”—enables one to solve directly for the Pareto index \\(\\alpha\\). This simplicity makes the Pareto distribution a convenient model or approximation for global wealth distribution, although in practice the estimated \\(\\alpha\\) can vary greatly depending on the dataset, sampling, and specific segment of the population observed.\nIn wealth and income distribution analysis, pairing empirical Lorenz curves with Pareto modeling remains a powerful—if simplified—approach to gauging inequality. For both theoretical and practical reasons, it continues to be integral in economic research, policy discussions, and broader studies of social welfare. Meanwhile, connections to CRRA utility function illustrate that core economic principles and certain types of heavy‐tailed probabilistic behavior can share similar mathematical underpinnings."
  }
]